{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Books Recommendations using SVD vs SVD Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import accuracy, Dataset, Reader, SVD, BaselineOnly, PredictionImpossible\n",
    "from surprise.model_selection import train_test_split, cross_validate, KFold, GridSearchCV\n",
    "import random\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "from scipy.sparse.linalg import svds\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# having min_books_rated_by_user and min_rates_received_by_book to define what we treat as statistically significant\n",
    "# remove those records from ratings_df, which have those books with less than min_rates_received_by_book reviews and those users who have left less than min_books_rated_by_user reviews\n",
    "def leave_stat_sign_data(ratings_df, min_books_rated_by_user=5,min_rates_received_by_book=5):\n",
    "    #select only those books which were rated more than min_rates_received_by_book\n",
    "    groupped_r_books=ratings_df.groupby('Book-Title')['User-ID'].count()\n",
    "    titles_with_acceptable_rates_count=list(groupped_r_books[groupped_r_books>min_rates_received_by_book].index)\n",
    "    #select only those users (user_id) who rated more than min_books_rated_by_user books\n",
    "    groupped_r_users=ratings_df.groupby('User-ID')['Book-Rating'].count()\n",
    "    user_ids_with_acceptable_books_count_rated=list(groupped_r_users[groupped_r_users>min_books_rated_by_user].index)\n",
    "    # filter rating-user data to have only books/users of interest (which have highest rates count and rated highest number of books respectively)\n",
    "    rating_final_df=ratings_df[ratings_df['Book-Title'].isin(titles_with_acceptable_rates_count)&ratings_df['User-ID'].isin(user_ids_with_acceptable_books_count_rated)]\n",
    "    return rating_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define formula for calculation of rmse, having actual and predicted rates lists\n",
    "def rmse(actual_rates, predicted_rates):\n",
    "    error = actual_rates - predicted_rates\n",
    "    mean_square_error=sum([i*i for i in error])/len(error)\n",
    "    return math.sqrt(mean_square_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in such a ways that we have data for all the users in both train and test sets - to be used by pure SVD\n",
    "def train_test_split_SVD (rating_final_df, test_ratio = 0.1):\n",
    "    user_list = rating_final_df['User-ID'].unique() #list of all users\n",
    "    test_set = pd.DataFrame(columns=rating_final_df.columns) # reserve df for a train set\n",
    "    train_set = pd.DataFrame(columns=rating_final_df.columns) # reserve df for a test set\n",
    "    for user in user_list:\n",
    "        # for each user take their book/rating data \n",
    "        user_data_all = rating_final_df[rating_final_df['User-ID'] == user]\n",
    "        n = len(user_data_all)\n",
    "        user_data_all = user_data_all.reset_index()\n",
    "        user_data_all.drop('index', axis=1, inplace=True)\n",
    "        # split user data into train and test \n",
    "        test_size = int(test_ratio*n)\n",
    "\n",
    "        # randomly select roughtly 10% of rows for test set per user using random_state=1, so that result is reproducible\n",
    "        test = user_data_all.sample(n=test_size, random_state=1)  \n",
    "\n",
    "        # rows not selected for test set, assigned to train one\n",
    "        train = user_data_all.drop(test.index)\n",
    "\n",
    "        test_set = pd.concat([test_set, test], ignore_index=True)\n",
    "        train_set = pd.concat([train_set, train], ignore_index=True)\n",
    "    return (train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the performance over a different number of laatent factors k_set\n",
    "def test_rmse_SVD(train_set, test_set, k_set = [8, 20, 50, 100, 150]):\n",
    "    rmse_scores={}\n",
    "    over_mean=train_set['Book-Rating'].mean()\n",
    "    for l_f in k_set: \n",
    "        # Build the prediction matrix using the train_set\n",
    "        all_predictions_df = build_prediction_matrix_SVD(train_set, l_f)\n",
    "        \n",
    "#          / experiment if time allows\n",
    "#         merged_test_set = test_set.set_index(['User-ID', 'Book-Title'])\n",
    "#         predicted_ratings = all_predictions_df.stack().reindex(merged_test_set.index).fillna(over_mean)\n",
    "\n",
    "#         # Calculate RMSE for the current number of features\n",
    "#         current_rmse = rmse(merged_test_set['Book-Rating'], predicted_ratings.values)\n",
    "#         / experiment if time allows\n",
    "\n",
    "        # reserve a list for predicted ratings\n",
    "        pred = []\n",
    "        for i, row in test_set.iterrows():\n",
    "            user_id = row['User-ID']\n",
    "            book_title = row['Book-Title']  \n",
    "            if user_id in all_predictions_df.index.values and book_title in all_predictions_df.columns:\n",
    "                pred_rating = all_predictions_df.loc[user_id, book_title]\n",
    "            else:\n",
    "                # If the book or user is not in the train_set, use a default prediction\n",
    "                # which is the average of all ratings in the training set as a simple approach\n",
    "                pred_rating = over_mean   \n",
    "            pred.append(pred_rating)\n",
    "\n",
    "        # Calculate RMSE for the current number of features\n",
    "        current_rmse = rmse(test_set['Book-Rating'], pred)\n",
    "        rmse_scores[l_f]=current_rmse\n",
    "    return rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building pure SVD model\n",
    "def build_prediction_matrix_SVD(rating_input_df, latent_factors=70):\n",
    "# SVD finds a hidden feature space where the users and books they like have feature vectors that are closely aligned.\n",
    "# Build the model based on decomposing 'user-rates' matrix df_books_ratigs_user into 3 matrices U×sigma×Vt:\n",
    "# U matrix - represents the feature vectors corresponding to the users in the hidden feature space \n",
    "# sigma - represents\n",
    "# Vt matrix - represents the feature vectors corresponding to the books in the hidden feature space \n",
    "    # Pivot to obtain a matrix that stores original ratings given by users for books and fill sparse values with 0-s\n",
    "    df_books_ratigs_user=rating_input_df.pivot_table(index='User-ID', columns='Book-Title', values='Book-Rating').fillna(0)\n",
    "    # Normilize the data, using mean normalization.\n",
    "    data_original = df_books_ratigs_user.to_numpy() # vectorize the data\n",
    "    ratings_mean = np.mean(data_original, axis = 1) # find a mean per each vector (user)\n",
    "    normalized_data = data_original - ratings_mean.reshape(-1, 1) #subtract mean for each user from their ratings, which centers the ratings around 0 for each user\n",
    "    # Decompose the normilized matrix into 3, with k = latent_factors (70 default) largest singular values in sigma\n",
    "    U, sigma, Vt = svds(normalized_data, k = latent_factors)\n",
    "    # Convert vector to a diagonal matrix\n",
    "    sigma = np.diag(sigma)\n",
    "    # Compose matrix with predictions, reversing data normalization\n",
    "    # e.g. having two vectors from the same feature space if we want to find if they are similar we need to find a Dot product.\n",
    "    # and to find out that user i likes book j, we would take the dot product of the i-th entry in U and j-th entry in Vt.\n",
    "    all_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + ratings_mean.reshape(-1, 1)\n",
    "    # convert numpy array into dataframe\n",
    "    all_predictions_df = pd.DataFrame(all_predicted_ratings, columns=df_books_ratigs_user.columns, index=df_books_ratigs_user.index)\n",
    "    return all_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find books prediction for a specific user and recommend top recommendations_count books\n",
    "def recommend_books_for_user (user_id, ratings_df, books_df, recommendations_count=5, model=None, all_predictions=None):\n",
    "# find those titles that we consider for predictions (e.g. not read by a user)\n",
    "    # find the books (titles) that were rated and presumably read by a user\n",
    "    rated_titles=[i for i in ratings_df.loc[ratings_df['User-ID']==user_id,'Book-Title']]\n",
    "    # find all the titles within the matrix\n",
    "    if model is None:\n",
    "        all_titles=all_predictions.columns\n",
    "    else:\n",
    "        all_titles=ratings_df['Book-Title'].unique()\n",
    "    # separate those titles that were not read\n",
    "    titles_input_to_recommend=[i for i in all_titles if i not in rated_titles]\n",
    "    \n",
    "# find predictions for a user\n",
    "    if model is None:\n",
    "        user_predictions_all=all_predictions.loc[user_id]\n",
    "        # sort predictions and select top recommendations_count\n",
    "        user_predictions_all=pd.DataFrame(user_predictions_all)\n",
    "        user_recommendation= user_predictions_all.loc[titles_input_to_recommend].sort_values(by=user_id, ascending=False)\n",
    "        top_recommendations=user_recommendation[:recommendations_count].rename(columns={user_id:'estimated rate'})\n",
    "    else:\n",
    "        # find predictions for a user\n",
    "        # reference: https://surprise.readthedocs.io/en/stable/algobase.html?highlight=predict\n",
    "        # uid – (Raw) id of the user. \n",
    "        # iid – (Raw) id of the item.\n",
    "        # verbose (bool) – Whether to print details of the prediction. Default is False.\n",
    "        predictions=[model.predict(uid=user_id, iid=i) for i in titles_input_to_recommend]\n",
    "        # get ratings estimate for books by the user\n",
    "        ratings=[i.est for i in predictions]\n",
    "        # convert predicted estimates by the user for not read books into df\n",
    "        pred_dict={\n",
    "            'Book-Title':titles_input_to_recommend,\n",
    "            'Estimated_Rate':ratings}\n",
    "        predictions_book=pd.DataFrame(pred_dict).sort_values('Estimated_Rate',ascending = False)\n",
    "        top_recommendations=predictions_book.head(recommendations_count)\n",
    "        \n",
    "# populate books with full info, selecting those books with the most recent year of publication\n",
    "    recommendations_full_info=pd.merge(top_recommendations, books_df, left_on='Book-Title',right_on='Book-Title', how='left')\n",
    "    dict_years=dict(recommendations_full_info.groupby('Book-Title')['Year-Of-Publication'].max())\n",
    "    for i, row in recommendations_full_info.iterrows():\n",
    "        if row['Year-Of-Publication']!=dict_years[row['Book-Title']]:\n",
    "            recommendations_full_info.loc[i,'Year-Of-Publication']=0\n",
    "    recommendations_full_info=recommendations_full_info[recommendations_full_info['Year-Of-Publication'] != 0]\n",
    "    recommendations_full_info=recommendations_full_info.drop_duplicates(subset=['Book-Title'])\n",
    "    return recommendations_full_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data and Prepare for Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/t4y_09d901v7s2qw9dqk8jzw0000gn/T/ipykernel_82728/1936971218.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books_df_original = pd.read_csv('./Resources/Books.csv')\n"
     ]
    }
   ],
   "source": [
    "#Creating dataframes from csv files to read the data\n",
    "books_df_original = pd.read_csv('./Resources/Books.csv')\n",
    "ratings_df_original = pd.read_csv('./Resources/Ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicated books records if any by looking at ISBN\n",
    "books_df=books_df_original.copy()\n",
    "books_df=books_df.drop_duplicates(subset=['ISBN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75637</th>\n",
       "      <td>1565920465</td>\n",
       "      <td>!%@ (A Nutshell handbook)</td>\n",
       "      <td>Donnalyn Frey</td>\n",
       "      <td>1994</td>\n",
       "      <td>O'Reilly</td>\n",
       "      <td>http://images.amazon.com/images/P/1565920465.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1565920465.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1565920465.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156341</th>\n",
       "      <td>1565920317</td>\n",
       "      <td>!%@ (A Nutshell handbook)</td>\n",
       "      <td>Donnalyn Frey</td>\n",
       "      <td>1993</td>\n",
       "      <td>O'Reilly</td>\n",
       "      <td>http://images.amazon.com/images/P/1565920317.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1565920317.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1565920317.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN                 Book-Title    Book-Author  \\\n",
       "75637   1565920465  !%@ (A Nutshell handbook)  Donnalyn Frey   \n",
       "156341  1565920317  !%@ (A Nutshell handbook)  Donnalyn Frey   \n",
       "\n",
       "       Year-Of-Publication Publisher  \\\n",
       "75637                 1994  O'Reilly   \n",
       "156341                1993  O'Reilly   \n",
       "\n",
       "                                              Image-URL-S  \\\n",
       "75637   http://images.amazon.com/images/P/1565920465.0...   \n",
       "156341  http://images.amazon.com/images/P/1565920317.0...   \n",
       "\n",
       "                                              Image-URL-M  \\\n",
       "75637   http://images.amazon.com/images/P/1565920465.0...   \n",
       "156341  http://images.amazon.com/images/P/1565920317.0...   \n",
       "\n",
       "                                              Image-URL-L  \n",
       "75637   http://images.amazon.com/images/P/1565920465.0...  \n",
       "156341  http://images.amazon.com/images/P/1565920317.0...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_titles=books_df[books_df.duplicated(subset=['Book-Title'],keep=False)].sort_values(by='Book-Title')\n",
    "duplicated_titles.head(2)\n",
    "# so far we leave those titles as is to not lost ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 266739 entries, 0 to 271359\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   ISBN                 266739 non-null  object\n",
      " 1   Book-Title           266739 non-null  object\n",
      " 2   Book-Author          266737 non-null  object\n",
      " 3   Year-Of-Publication  266739 non-null  int64 \n",
      " 4   Publisher            266737 non-null  object\n",
      " 5   Image-URL-S          266739 non-null  object\n",
      " 6   Image-URL-M          266739 non-null  object\n",
      " 7   Image-URL-L          266739 non-null  object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 18.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# update the datatype of a 'Year-Of-Publication' field to numeric one\n",
    "books_df['Year-Of-Publication']=pd.to_numeric(books_df['Year-Of-Publication'],errors='coerce')\n",
    "# Filter out data with no publication year\n",
    "books_df = books_df[books_df['Year-Of-Publication'] > 0]\n",
    "books_df['Year-Of-Publication']=books_df['Year-Of-Publication'].astype(int)\n",
    "# and check the result\n",
    "books_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1149780 entries, 0 to 1149779\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   User-ID      1149780 non-null  int64 \n",
      " 1   ISBN         1149780 non-null  object\n",
      " 2   Book-Rating  1149780 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 26.3+ MB\n"
     ]
    }
   ],
   "source": [
    "ratings_df=ratings_df_original.copy()\n",
    "# update the datatype of a 'Book-Rating' field to numeric one\n",
    "ratings_df['Book-Rating']=pd.to_numeric(ratings_df['Book-Rating'],errors='coerce')\n",
    "# and check the result\n",
    "ratings_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change ISBN with Titles\n",
    "Merge ratings with books data in order to change isbn with title and leave only those ratings data for which we have title info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN           Book-Title           Book-Author  Year-Of-Publication  \\\n",
       "0  0195153448  Classical Mythology    Mark P. O. Morford                 2002   \n",
       "1  0002005018         Clara Callan  Richard Bruce Wright                 2001   \n",
       "\n",
       "                 Publisher                                        Image-URL-S  \\\n",
       "0  Oxford University Press  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "\n",
       "                                         Image-URL-L  User-ID  Book-Rating  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...        2            0  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...        8            5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df=pd.merge(books_df,ratings_df,on='ISBN', how = 'inner')\n",
    "ratings_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Book-Title  User-ID  Book-Rating\n",
       "0  Classical Mythology        2            0\n",
       "1         Clara Callan        8            5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete those rows with no book titles or no book rates if any (even though there should no be such as we used inner join above)\n",
    "ratings_df=ratings_df.dropna()\n",
    "ratings_df_all_cols=ratings_df.copy()\n",
    "# delete those columns, which we are not going to use within machine learning algos\n",
    "ratings_df=ratings_df.drop(['ISBN','Book-Author','Year-Of-Publication','Publisher','Image-URL-S','Image-URL-M','Image-URL-L'], axis=1)\n",
    "ratings_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out data with zero ratings\n",
    "ratings_df_no_zeros = ratings_df[ratings_df['Book-Rating'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Storm: The Civil War Diary of ...</td>\n",
       "      <td>96448</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ask Lily (Young Women of Faith: Lily Series, ...</td>\n",
       "      <td>269557</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Book-Title  User-ID  Book-Rating\n",
       "0   A Light in the Storm: The Civil War Diary of ...    96448          9.0\n",
       "1   Ask Lily (Young Women of Faith: Lily Series, ...   269557          8.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use avg rate per duplicates set for three: ratings_df, ratings_df_adj and ratings_df_no_zeros\n",
    "ratings_df_no_zeros=ratings_df_no_zeros.groupby(['Book-Title','User-ID'])['Book-Rating'].mean().reset_index()\n",
    "ratings_df_no_zeros.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave only statistically significant data for both ratings_df_adj and ratings_df_no_zeros\n",
    "rating_final_no_zeros_df=leave_stat_sign_data(ratings_df_no_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure SVD model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_no_zeros, test_set_no_zeros = train_test_split_SVD(rating_final_no_zeros_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Generation of a matrix with predicted rates per book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_predictions_no_zeros=build_prediction_matrix_SVD(rating_final_no_zeros_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Book-Title</th>\n",
       "      <th>Earth Prayers From around the World: 365 Prayers, Poems, and Invocations for Honoring the Earth</th>\n",
       "      <th>!Yo!</th>\n",
       "      <th>'Salem's Lot</th>\n",
       "      <th>01-01-00: The Novel of the Millennium</th>\n",
       "      <th>10 Lb. Penalty</th>\n",
       "      <th>10,000 dreams interpreted: A dictionary of dreams</th>\n",
       "      <th>100 Best-Loved Poems (Dover Thrift Editions)</th>\n",
       "      <th>100 Selected Poems by E. E. Cummings</th>\n",
       "      <th>1001 Things Everyone Should Know About Science</th>\n",
       "      <th>1001 Ways to Be Romantic</th>\n",
       "      <th>...</th>\n",
       "      <th>\\O\\\" Is for Outlaw\"</th>\n",
       "      <th>\\Surely You're Joking, Mr. Feynman!\\\": Adventures of a Curious Character\"</th>\n",
       "      <th>\\The Happy Prince\\\" and Other Stories (Penguin Popular Classics)\"</th>\n",
       "      <th>\\What Do You Care What Other People Think?\\\": Further Adventures of a Curious Character\"</th>\n",
       "      <th>e</th>\n",
       "      <th>iI Paradiso Degli Orchi</th>\n",
       "      <th>murder@maggody.com : An Arly Hanks Mystery (Arly Hanks Mysteries (Paperback))</th>\n",
       "      <th>one hundred years of solitude</th>\n",
       "      <th>stardust</th>\n",
       "      <th>why I'm like this : True Stories</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User-ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>-0.000336</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001038</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>-0.000644</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>-0.001974</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.005974</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003512</td>\n",
       "      <td>0.003680</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.002110</td>\n",
       "      <td>-0.006801</td>\n",
       "      <td>0.003581</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>-0.000692</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.005465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.008808</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>-0.035543</td>\n",
       "      <td>0.056729</td>\n",
       "      <td>-0.069261</td>\n",
       "      <td>-0.004213</td>\n",
       "      <td>-0.017281</td>\n",
       "      <td>-0.038169</td>\n",
       "      <td>-0.009262</td>\n",
       "      <td>-0.017620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026166</td>\n",
       "      <td>-0.008591</td>\n",
       "      <td>0.045725</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.084810</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>-0.011920</td>\n",
       "      <td>-0.037713</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>-0.015035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>-0.008163</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0.098813</td>\n",
       "      <td>-0.010835</td>\n",
       "      <td>-0.032621</td>\n",
       "      <td>-0.001764</td>\n",
       "      <td>0.027848</td>\n",
       "      <td>0.026195</td>\n",
       "      <td>-0.014049</td>\n",
       "      <td>-0.000306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094758</td>\n",
       "      <td>0.051785</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>-0.002696</td>\n",
       "      <td>-0.036294</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.008610</td>\n",
       "      <td>-0.009145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>-0.014596</td>\n",
       "      <td>0.012220</td>\n",
       "      <td>-0.086185</td>\n",
       "      <td>0.010529</td>\n",
       "      <td>-0.020236</td>\n",
       "      <td>0.017999</td>\n",
       "      <td>-0.026686</td>\n",
       "      <td>0.084581</td>\n",
       "      <td>0.043281</td>\n",
       "      <td>0.061944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477174</td>\n",
       "      <td>0.006837</td>\n",
       "      <td>-0.021648</td>\n",
       "      <td>-0.008918</td>\n",
       "      <td>-0.029811</td>\n",
       "      <td>-0.009990</td>\n",
       "      <td>0.006611</td>\n",
       "      <td>-0.012845</td>\n",
       "      <td>-0.077676</td>\n",
       "      <td>0.009178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278633</th>\n",
       "      <td>0.016941</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>-0.037586</td>\n",
       "      <td>-0.017051</td>\n",
       "      <td>-0.066762</td>\n",
       "      <td>0.008461</td>\n",
       "      <td>-0.022465</td>\n",
       "      <td>0.025970</td>\n",
       "      <td>0.041588</td>\n",
       "      <td>0.060244</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240852</td>\n",
       "      <td>-0.059897</td>\n",
       "      <td>-0.012479</td>\n",
       "      <td>-0.003743</td>\n",
       "      <td>0.042439</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>0.017967</td>\n",
       "      <td>-0.154048</td>\n",
       "      <td>0.055585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278694</th>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.002294</td>\n",
       "      <td>-0.002261</td>\n",
       "      <td>0.008578</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.003144</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047935</td>\n",
       "      <td>0.003106</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.005401</td>\n",
       "      <td>0.001730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278843</th>\n",
       "      <td>-0.011425</td>\n",
       "      <td>-0.027014</td>\n",
       "      <td>0.051353</td>\n",
       "      <td>-0.000474</td>\n",
       "      <td>0.025538</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>-0.041905</td>\n",
       "      <td>0.053412</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107071</td>\n",
       "      <td>0.039368</td>\n",
       "      <td>-0.010670</td>\n",
       "      <td>-0.004503</td>\n",
       "      <td>0.190347</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.106894</td>\n",
       "      <td>0.067311</td>\n",
       "      <td>-0.024405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278851</th>\n",
       "      <td>0.004294</td>\n",
       "      <td>-0.000494</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>0.007322</td>\n",
       "      <td>-0.000608</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>-0.006946</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053799</td>\n",
       "      <td>-0.001106</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>-0.003663</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.003435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278854</th>\n",
       "      <td>-0.002948</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>-0.013191</td>\n",
       "      <td>-0.010001</td>\n",
       "      <td>-0.001670</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>-0.007729</td>\n",
       "      <td>-0.010469</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068115</td>\n",
       "      <td>-0.006778</td>\n",
       "      <td>-0.002054</td>\n",
       "      <td>-0.000785</td>\n",
       "      <td>0.011607</td>\n",
       "      <td>-0.001603</td>\n",
       "      <td>-0.002093</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>-0.010139</td>\n",
       "      <td>-0.003090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10348 rows × 10654 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Book-Title   Earth Prayers From around the World: 365 Prayers, Poems, and Invocations for Honoring the Earth  \\\n",
       "User-ID                                                                                                        \n",
       "8                                                    0.000245                                                  \n",
       "99                                                   0.002913                                                  \n",
       "114                                                  0.008808                                                  \n",
       "242                                                 -0.008163                                                  \n",
       "243                                                 -0.014596                                                  \n",
       "...                                                       ...                                                  \n",
       "278633                                               0.016941                                                  \n",
       "278694                                               0.002407                                                  \n",
       "278843                                              -0.011425                                                  \n",
       "278851                                               0.004294                                                  \n",
       "278854                                              -0.002948                                                  \n",
       "\n",
       "Book-Title      !Yo!  'Salem's Lot  01-01-00: The Novel of the Millennium  \\\n",
       "User-ID                                                                     \n",
       "8           0.000219      0.000056                               0.002000   \n",
       "99          0.003248      0.001333                              -0.001974   \n",
       "114         0.000331     -0.035543                               0.056729   \n",
       "242         0.002806      0.098813                              -0.010835   \n",
       "243         0.012220     -0.086185                               0.010529   \n",
       "...              ...           ...                                    ...   \n",
       "278633      0.003876     -0.037586                              -0.017051   \n",
       "278694      0.002294     -0.002261                               0.008578   \n",
       "278843     -0.027014      0.051353                              -0.000474   \n",
       "278851     -0.000494      0.027033                               0.007322   \n",
       "278854      0.000643     -0.013191                              -0.010001   \n",
       "\n",
       "Book-Title  10 Lb. Penalty  10,000 dreams interpreted: A dictionary of dreams  \\\n",
       "User-ID                                                                         \n",
       "8                -0.000336                                           0.000394   \n",
       "99                0.002214                                          -0.000002   \n",
       "114              -0.069261                                          -0.004213   \n",
       "242              -0.032621                                          -0.001764   \n",
       "243              -0.020236                                           0.017999   \n",
       "...                    ...                                                ...   \n",
       "278633           -0.066762                                           0.008461   \n",
       "278694            0.001928                                           0.002335   \n",
       "278843            0.025538                                           0.002019   \n",
       "278851           -0.000608                                           0.000668   \n",
       "278854           -0.001670                                           0.000906   \n",
       "\n",
       "Book-Title  100 Best-Loved Poems (Dover Thrift Editions)  \\\n",
       "User-ID                                                    \n",
       "8                                               0.000052   \n",
       "99                                              0.004381   \n",
       "114                                            -0.017281   \n",
       "242                                             0.027848   \n",
       "243                                            -0.026686   \n",
       "...                                                  ...   \n",
       "278633                                         -0.022465   \n",
       "278694                                          0.000164   \n",
       "278843                                         -0.041905   \n",
       "278851                                          0.000108   \n",
       "278854                                         -0.007729   \n",
       "\n",
       "Book-Title  100 Selected Poems by E. E. Cummings  \\\n",
       "User-ID                                            \n",
       "8                                       0.000047   \n",
       "99                                      0.001519   \n",
       "114                                    -0.038169   \n",
       "242                                     0.026195   \n",
       "243                                     0.084581   \n",
       "...                                          ...   \n",
       "278633                                  0.025970   \n",
       "278694                                  0.003819   \n",
       "278843                                  0.053412   \n",
       "278851                                  0.000076   \n",
       "278854                                 -0.010469   \n",
       "\n",
       "Book-Title  1001 Things Everyone Should Know About Science  \\\n",
       "User-ID                                                      \n",
       "8                                                -0.000200   \n",
       "99                                                0.005974   \n",
       "114                                              -0.009262   \n",
       "242                                              -0.014049   \n",
       "243                                               0.043281   \n",
       "...                                                    ...   \n",
       "278633                                            0.041588   \n",
       "278694                                            0.003144   \n",
       "278843                                            0.000979   \n",
       "278851                                           -0.006946   \n",
       "278854                                            0.016800   \n",
       "\n",
       "Book-Title  1001 Ways to Be Romantic  ...  \\O\\\" Is for Outlaw\"  \\\n",
       "User-ID                               ...                        \n",
       "8                           0.000140  ...            -0.001038   \n",
       "99                          0.004444  ...            -0.003512   \n",
       "114                        -0.017620  ...             0.026166   \n",
       "242                        -0.000306  ...            -0.094758   \n",
       "243                         0.061944  ...             0.477174   \n",
       "...                              ...  ...                  ...   \n",
       "278633                      0.060244  ...            -0.240852   \n",
       "278694                      0.003134  ...             0.047935   \n",
       "278843                      0.002522  ...             0.107071   \n",
       "278851                      0.001850  ...             0.053799   \n",
       "278854                      0.005030  ...             0.068115   \n",
       "\n",
       "Book-Title  \\Surely You're Joking, Mr. Feynman!\\\": Adventures of a Curious Character\"  \\\n",
       "User-ID                                                                                 \n",
       "8                                                    0.001280                           \n",
       "99                                                   0.003680                           \n",
       "114                                                 -0.008591                           \n",
       "242                                                  0.051785                           \n",
       "243                                                  0.006837                           \n",
       "...                                                       ...                           \n",
       "278633                                              -0.059897                           \n",
       "278694                                               0.003106                           \n",
       "278843                                               0.039368                           \n",
       "278851                                              -0.001106                           \n",
       "278854                                              -0.006778                           \n",
       "\n",
       "Book-Title  \\The Happy Prince\\\" and Other Stories (Penguin Popular Classics)\"  \\\n",
       "User-ID                                                                         \n",
       "8                                                    0.000396                   \n",
       "99                                                   0.002735                   \n",
       "114                                                  0.045725                   \n",
       "242                                                 -0.000270                   \n",
       "243                                                 -0.021648                   \n",
       "...                                                       ...                   \n",
       "278633                                              -0.012479                   \n",
       "278694                                               0.002439                   \n",
       "278843                                              -0.010670                   \n",
       "278851                                               0.000382                   \n",
       "278854                                              -0.002054                   \n",
       "\n",
       "Book-Title  \\What Do You Care What Other People Think?\\\": Further Adventures of a Curious Character\"  \\\n",
       "User-ID                                                                                                \n",
       "8                                                    0.000330                                          \n",
       "99                                                   0.002110                                          \n",
       "114                                                  0.002359                                          \n",
       "242                                                 -0.002696                                          \n",
       "243                                                 -0.008918                                          \n",
       "...                                                       ...                                          \n",
       "278633                                              -0.003743                                          \n",
       "278694                                               0.002280                                          \n",
       "278843                                              -0.004503                                          \n",
       "278851                                               0.001553                                          \n",
       "278854                                              -0.000785                                          \n",
       "\n",
       "Book-Title         e  iI Paradiso Degli Orchi  \\\n",
       "User-ID                                         \n",
       "8          -0.000644                 0.000353   \n",
       "99         -0.006801                 0.003581   \n",
       "114         0.084810                 0.001898   \n",
       "242        -0.036294                 0.000138   \n",
       "243        -0.029811                -0.009990   \n",
       "...              ...                      ...   \n",
       "278633      0.042439                 0.004137   \n",
       "278694      0.001762                 0.002784   \n",
       "278843      0.190347                 0.002539   \n",
       "278851     -0.003663                 0.000477   \n",
       "278854      0.011607                -0.001603   \n",
       "\n",
       "Book-Title  murder@maggody.com : An Arly Hanks Mystery (Arly Hanks Mysteries (Paperback))  \\\n",
       "User-ID                                                                                     \n",
       "8                                                    0.000510                               \n",
       "99                                                   0.006024                               \n",
       "114                                                 -0.011920                               \n",
       "242                                                  0.000584                               \n",
       "243                                                  0.006611                               \n",
       "...                                                       ...                               \n",
       "278633                                               0.008666                               \n",
       "278694                                               0.001542                               \n",
       "278843                                               0.005742                               \n",
       "278851                                              -0.000195                               \n",
       "278854                                              -0.002093                               \n",
       "\n",
       "Book-Title  one hundred years of solitude  stardust  \\\n",
       "User-ID                                               \n",
       "8                                0.000039  0.002024   \n",
       "99                              -0.000692  0.003367   \n",
       "114                             -0.037713 -0.021000   \n",
       "242                              0.000879  0.008610   \n",
       "243                             -0.012845 -0.077676   \n",
       "...                                   ...       ...   \n",
       "278633                           0.017967 -0.154048   \n",
       "278694                           0.002566  0.005401   \n",
       "278843                           0.106894  0.067311   \n",
       "278851                           0.001884  0.002360   \n",
       "278854                          -0.008983 -0.010139   \n",
       "\n",
       "Book-Title  why I'm like this : True Stories  \n",
       "User-ID                                       \n",
       "8                                   0.000403  \n",
       "99                                  0.005465  \n",
       "114                                -0.015035  \n",
       "242                                -0.009145  \n",
       "243                                 0.009178  \n",
       "...                                      ...  \n",
       "278633                              0.055585  \n",
       "278694                              0.001730  \n",
       "278843                             -0.024405  \n",
       "278851                              0.003435  \n",
       "278854                             -0.003090  \n",
       "\n",
       "[10348 rows x 10654 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions_no_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_scores_no_zeros = test_rmse_SVD(train_set_no_zeros, test_set_no_zeros)\n",
    "print('Accuracy for data with no 0 ratings (number of latent factors, RMSE):')\n",
    "display(rmse_scores_no_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check predictions for specific user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find original user ratings\n",
    "u_data=ratings_df_all_cols[ratings_df_all_cols['User-ID']==252676].sort_values(by='Book-Rating', ascending=False)\n",
    "u_data[['User-ID','Book-Title','Book-Rating','Book-Author','Year-Of-Publication','Publisher']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview recommendations by pure SVD (mean)\n",
    "recommend_books_for_user(252676, ratings_df, books_df, all_predictions=all_predictions_no_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
