{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 - Books Recommendation using SVD\n",
    "Collaborative based filtering->Item based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import accuracy, Dataset, Reader, SVD, BaselineOnly, PredictionImpossible\n",
    "from surprise.model_selection import train_test_split, cross_validate, KFold, GridSearchCV\n",
    "import random\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "from scipy.sparse.linalg import svds\n",
    "import math "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data and Prepare for Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3g/t4y_09d901v7s2qw9dqk8jzw0000gn/T/ipykernel_1291/1936971218.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books_df_original = pd.read_csv('./Resources/Books.csv')\n"
     ]
    }
   ],
   "source": [
    "#Creating dataframes from csv files to read the data\n",
    "books_df_original = pd.read_csv('./Resources/Books.csv')\n",
    "ratings_df_original = pd.read_csv('./Resources/Ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicated books records if any by looking at ISBN\n",
    "books_df=books_df_original.copy()\n",
    "books_df=books_df.drop_duplicates(subset=['ISBN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75637</th>\n",
       "      <td>1565920465</td>\n",
       "      <td>!%@ (A Nutshell handbook)</td>\n",
       "      <td>Donnalyn Frey</td>\n",
       "      <td>1994</td>\n",
       "      <td>O'Reilly</td>\n",
       "      <td>http://images.amazon.com/images/P/1565920465.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1565920465.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1565920465.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156341</th>\n",
       "      <td>1565920317</td>\n",
       "      <td>!%@ (A Nutshell handbook)</td>\n",
       "      <td>Donnalyn Frey</td>\n",
       "      <td>1993</td>\n",
       "      <td>O'Reilly</td>\n",
       "      <td>http://images.amazon.com/images/P/1565920317.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1565920317.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1565920317.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140618</th>\n",
       "      <td>0792276833</td>\n",
       "      <td>'A Hell of a Place to Lose a Cow': An American...</td>\n",
       "      <td>Tim Brookes</td>\n",
       "      <td>2000</td>\n",
       "      <td>National Geographic</td>\n",
       "      <td>http://images.amazon.com/images/P/0792276833.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0792276833.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0792276833.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158204</th>\n",
       "      <td>0792277295</td>\n",
       "      <td>'A Hell of a Place to Lose a Cow': An American...</td>\n",
       "      <td>Tim Brookes</td>\n",
       "      <td>2001</td>\n",
       "      <td>National Geographic</td>\n",
       "      <td>http://images.amazon.com/images/P/0792277295.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0792277295.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0792277295.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10438</th>\n",
       "      <td>0451168089</td>\n",
       "      <td>'Salem's Lot</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td>1990</td>\n",
       "      <td>Signet Book</td>\n",
       "      <td>http://images.amazon.com/images/P/0451168089.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0451168089.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0451168089.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN                                         Book-Title  \\\n",
       "75637   1565920465                          !%@ (A Nutshell handbook)   \n",
       "156341  1565920317                          !%@ (A Nutshell handbook)   \n",
       "140618  0792276833  'A Hell of a Place to Lose a Cow': An American...   \n",
       "158204  0792277295  'A Hell of a Place to Lose a Cow': An American...   \n",
       "10438   0451168089                                       'Salem's Lot   \n",
       "\n",
       "          Book-Author Year-Of-Publication            Publisher  \\\n",
       "75637   Donnalyn Frey                1994             O'Reilly   \n",
       "156341  Donnalyn Frey                1993             O'Reilly   \n",
       "140618    Tim Brookes                2000  National Geographic   \n",
       "158204    Tim Brookes                2001  National Geographic   \n",
       "10438    Stephen King                1990          Signet Book   \n",
       "\n",
       "                                              Image-URL-S  \\\n",
       "75637   http://images.amazon.com/images/P/1565920465.0...   \n",
       "156341  http://images.amazon.com/images/P/1565920317.0...   \n",
       "140618  http://images.amazon.com/images/P/0792276833.0...   \n",
       "158204  http://images.amazon.com/images/P/0792277295.0...   \n",
       "10438   http://images.amazon.com/images/P/0451168089.0...   \n",
       "\n",
       "                                              Image-URL-M  \\\n",
       "75637   http://images.amazon.com/images/P/1565920465.0...   \n",
       "156341  http://images.amazon.com/images/P/1565920317.0...   \n",
       "140618  http://images.amazon.com/images/P/0792276833.0...   \n",
       "158204  http://images.amazon.com/images/P/0792277295.0...   \n",
       "10438   http://images.amazon.com/images/P/0451168089.0...   \n",
       "\n",
       "                                              Image-URL-L  \n",
       "75637   http://images.amazon.com/images/P/1565920465.0...  \n",
       "156341  http://images.amazon.com/images/P/1565920317.0...  \n",
       "140618  http://images.amazon.com/images/P/0792276833.0...  \n",
       "158204  http://images.amazon.com/images/P/0792277295.0...  \n",
       "10438   http://images.amazon.com/images/P/0451168089.0...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_titles=books_df[books_df.duplicated(subset=['Book-Title'],keep=False)].sort_values(by='Book-Title')\n",
    "duplicated_titles.head()\n",
    "# so far we leave those titles as is to not lost ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 266739 entries, 0 to 271359\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   ISBN                 266739 non-null  object\n",
      " 1   Book-Title           266739 non-null  object\n",
      " 2   Book-Author          266737 non-null  object\n",
      " 3   Year-Of-Publication  266739 non-null  int64 \n",
      " 4   Publisher            266737 non-null  object\n",
      " 5   Image-URL-S          266739 non-null  object\n",
      " 6   Image-URL-M          266739 non-null  object\n",
      " 7   Image-URL-L          266739 non-null  object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 18.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# update the datatype of a 'Year-Of-Publication' field to numeric one\n",
    "books_df['Year-Of-Publication']=pd.to_numeric(books_df['Year-Of-Publication'],errors='coerce')\n",
    "# Filter out data with no publication year\n",
    "books_df = books_df[books_df['Year-Of-Publication'] > 0]\n",
    "books_df['Year-Of-Publication']=books_df['Year-Of-Publication'].astype(int)\n",
    "# and check the result\n",
    "books_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1149780 entries, 0 to 1149779\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   User-ID      1149780 non-null  int64 \n",
      " 1   ISBN         1149780 non-null  object\n",
      " 2   Book-Rating  1149780 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 26.3+ MB\n"
     ]
    }
   ],
   "source": [
    "ratings_df=ratings_df_original.copy()\n",
    "# update the datatype of a 'Book-Rating' field to numeric one\n",
    "ratings_df['Book-Rating']=pd.to_numeric(ratings_df['Book-Rating'],errors='coerce')\n",
    "# and check the result\n",
    "ratings_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change ISBN with Titles\n",
    "Merge ratings with books data in order to change isbn with title and leave only those ratings data for which we have title info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>11400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>11676</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>41385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017118</th>\n",
       "      <td>0440400988</td>\n",
       "      <td>There's a Bat in Bunk Five</td>\n",
       "      <td>Paula Danziger</td>\n",
       "      <td>1988</td>\n",
       "      <td>Random House Childrens Pub (Mm)</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>276463</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017119</th>\n",
       "      <td>0525447644</td>\n",
       "      <td>From One to One Hundred</td>\n",
       "      <td>Teri Sloat</td>\n",
       "      <td>1991</td>\n",
       "      <td>Dutton Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>276579</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017120</th>\n",
       "      <td>006008667X</td>\n",
       "      <td>Lily Dale : The True Story of the Town that Ta...</td>\n",
       "      <td>Christine Wicker</td>\n",
       "      <td>2004</td>\n",
       "      <td>HarperSanFrancisco</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>276680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017121</th>\n",
       "      <td>0192126040</td>\n",
       "      <td>Republic (World's Classics)</td>\n",
       "      <td>Plato</td>\n",
       "      <td>1996</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>276680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017122</th>\n",
       "      <td>0767409752</td>\n",
       "      <td>A Guided Tour of Rene Descartes' Meditations o...</td>\n",
       "      <td>Christopher  Biffle</td>\n",
       "      <td>2000</td>\n",
       "      <td>McGraw-Hill Humanities/Social Sciences/Languages</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>276680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1017123 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ISBN                                         Book-Title  \\\n",
       "0        0195153448                                Classical Mythology   \n",
       "1        0002005018                                       Clara Callan   \n",
       "2        0002005018                                       Clara Callan   \n",
       "3        0002005018                                       Clara Callan   \n",
       "4        0002005018                                       Clara Callan   \n",
       "...             ...                                                ...   \n",
       "1017118  0440400988                         There's a Bat in Bunk Five   \n",
       "1017119  0525447644                            From One to One Hundred   \n",
       "1017120  006008667X  Lily Dale : The True Story of the Town that Ta...   \n",
       "1017121  0192126040                        Republic (World's Classics)   \n",
       "1017122  0767409752  A Guided Tour of Rene Descartes' Meditations o...   \n",
       "\n",
       "                  Book-Author  Year-Of-Publication  \\\n",
       "0          Mark P. O. Morford                 2002   \n",
       "1        Richard Bruce Wright                 2001   \n",
       "2        Richard Bruce Wright                 2001   \n",
       "3        Richard Bruce Wright                 2001   \n",
       "4        Richard Bruce Wright                 2001   \n",
       "...                       ...                  ...   \n",
       "1017118        Paula Danziger                 1988   \n",
       "1017119            Teri Sloat                 1991   \n",
       "1017120      Christine Wicker                 2004   \n",
       "1017121                 Plato                 1996   \n",
       "1017122   Christopher  Biffle                 2000   \n",
       "\n",
       "                                                Publisher  \\\n",
       "0                                 Oxford University Press   \n",
       "1                                   HarperFlamingo Canada   \n",
       "2                                   HarperFlamingo Canada   \n",
       "3                                   HarperFlamingo Canada   \n",
       "4                                   HarperFlamingo Canada   \n",
       "...                                                   ...   \n",
       "1017118                   Random House Childrens Pub (Mm)   \n",
       "1017119                                      Dutton Books   \n",
       "1017120                                HarperSanFrancisco   \n",
       "1017121                           Oxford University Press   \n",
       "1017122  McGraw-Hill Humanities/Social Sciences/Languages   \n",
       "\n",
       "                                               Image-URL-S  \\\n",
       "0        http://images.amazon.com/images/P/0195153448.0...   \n",
       "1        http://images.amazon.com/images/P/0002005018.0...   \n",
       "2        http://images.amazon.com/images/P/0002005018.0...   \n",
       "3        http://images.amazon.com/images/P/0002005018.0...   \n",
       "4        http://images.amazon.com/images/P/0002005018.0...   \n",
       "...                                                    ...   \n",
       "1017118  http://images.amazon.com/images/P/0440400988.0...   \n",
       "1017119  http://images.amazon.com/images/P/0525447644.0...   \n",
       "1017120  http://images.amazon.com/images/P/006008667X.0...   \n",
       "1017121  http://images.amazon.com/images/P/0192126040.0...   \n",
       "1017122  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                               Image-URL-M  \\\n",
       "0        http://images.amazon.com/images/P/0195153448.0...   \n",
       "1        http://images.amazon.com/images/P/0002005018.0...   \n",
       "2        http://images.amazon.com/images/P/0002005018.0...   \n",
       "3        http://images.amazon.com/images/P/0002005018.0...   \n",
       "4        http://images.amazon.com/images/P/0002005018.0...   \n",
       "...                                                    ...   \n",
       "1017118  http://images.amazon.com/images/P/0440400988.0...   \n",
       "1017119  http://images.amazon.com/images/P/0525447644.0...   \n",
       "1017120  http://images.amazon.com/images/P/006008667X.0...   \n",
       "1017121  http://images.amazon.com/images/P/0192126040.0...   \n",
       "1017122  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                               Image-URL-L  User-ID  \\\n",
       "0        http://images.amazon.com/images/P/0195153448.0...        2   \n",
       "1        http://images.amazon.com/images/P/0002005018.0...        8   \n",
       "2        http://images.amazon.com/images/P/0002005018.0...    11400   \n",
       "3        http://images.amazon.com/images/P/0002005018.0...    11676   \n",
       "4        http://images.amazon.com/images/P/0002005018.0...    41385   \n",
       "...                                                    ...      ...   \n",
       "1017118  http://images.amazon.com/images/P/0440400988.0...   276463   \n",
       "1017119  http://images.amazon.com/images/P/0525447644.0...   276579   \n",
       "1017120  http://images.amazon.com/images/P/006008667X.0...   276680   \n",
       "1017121  http://images.amazon.com/images/P/0192126040.0...   276680   \n",
       "1017122  http://images.amazon.com/images/P/0767409752.0...   276680   \n",
       "\n",
       "         Book-Rating  \n",
       "0                  0  \n",
       "1                  5  \n",
       "2                  0  \n",
       "3                  8  \n",
       "4                  0  \n",
       "...              ...  \n",
       "1017118            7  \n",
       "1017119            4  \n",
       "1017120            0  \n",
       "1017121            0  \n",
       "1017122            0  \n",
       "\n",
       "[1017123 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df=pd.merge(books_df,ratings_df,on='ISBN', how = 'inner')\n",
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>11400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>11676</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>41385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017118</th>\n",
       "      <td>0440400988</td>\n",
       "      <td>There's a Bat in Bunk Five</td>\n",
       "      <td>Paula Danziger</td>\n",
       "      <td>1988</td>\n",
       "      <td>Random House Childrens Pub (Mm)</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>276463</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017119</th>\n",
       "      <td>0525447644</td>\n",
       "      <td>From One to One Hundred</td>\n",
       "      <td>Teri Sloat</td>\n",
       "      <td>1991</td>\n",
       "      <td>Dutton Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>276579</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017120</th>\n",
       "      <td>006008667X</td>\n",
       "      <td>Lily Dale : The True Story of the Town that Ta...</td>\n",
       "      <td>Christine Wicker</td>\n",
       "      <td>2004</td>\n",
       "      <td>HarperSanFrancisco</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>276680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017121</th>\n",
       "      <td>0192126040</td>\n",
       "      <td>Republic (World's Classics)</td>\n",
       "      <td>Plato</td>\n",
       "      <td>1996</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>276680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017122</th>\n",
       "      <td>0767409752</td>\n",
       "      <td>A Guided Tour of Rene Descartes' Meditations o...</td>\n",
       "      <td>Christopher  Biffle</td>\n",
       "      <td>2000</td>\n",
       "      <td>McGraw-Hill Humanities/Social Sciences/Languages</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>276680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1017119 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ISBN                                         Book-Title  \\\n",
       "0        0195153448                                Classical Mythology   \n",
       "1        0002005018                                       Clara Callan   \n",
       "2        0002005018                                       Clara Callan   \n",
       "3        0002005018                                       Clara Callan   \n",
       "4        0002005018                                       Clara Callan   \n",
       "...             ...                                                ...   \n",
       "1017118  0440400988                         There's a Bat in Bunk Five   \n",
       "1017119  0525447644                            From One to One Hundred   \n",
       "1017120  006008667X  Lily Dale : The True Story of the Town that Ta...   \n",
       "1017121  0192126040                        Republic (World's Classics)   \n",
       "1017122  0767409752  A Guided Tour of Rene Descartes' Meditations o...   \n",
       "\n",
       "                  Book-Author  Year-Of-Publication  \\\n",
       "0          Mark P. O. Morford                 2002   \n",
       "1        Richard Bruce Wright                 2001   \n",
       "2        Richard Bruce Wright                 2001   \n",
       "3        Richard Bruce Wright                 2001   \n",
       "4        Richard Bruce Wright                 2001   \n",
       "...                       ...                  ...   \n",
       "1017118        Paula Danziger                 1988   \n",
       "1017119            Teri Sloat                 1991   \n",
       "1017120      Christine Wicker                 2004   \n",
       "1017121                 Plato                 1996   \n",
       "1017122   Christopher  Biffle                 2000   \n",
       "\n",
       "                                                Publisher  \\\n",
       "0                                 Oxford University Press   \n",
       "1                                   HarperFlamingo Canada   \n",
       "2                                   HarperFlamingo Canada   \n",
       "3                                   HarperFlamingo Canada   \n",
       "4                                   HarperFlamingo Canada   \n",
       "...                                                   ...   \n",
       "1017118                   Random House Childrens Pub (Mm)   \n",
       "1017119                                      Dutton Books   \n",
       "1017120                                HarperSanFrancisco   \n",
       "1017121                           Oxford University Press   \n",
       "1017122  McGraw-Hill Humanities/Social Sciences/Languages   \n",
       "\n",
       "                                               Image-URL-S  \\\n",
       "0        http://images.amazon.com/images/P/0195153448.0...   \n",
       "1        http://images.amazon.com/images/P/0002005018.0...   \n",
       "2        http://images.amazon.com/images/P/0002005018.0...   \n",
       "3        http://images.amazon.com/images/P/0002005018.0...   \n",
       "4        http://images.amazon.com/images/P/0002005018.0...   \n",
       "...                                                    ...   \n",
       "1017118  http://images.amazon.com/images/P/0440400988.0...   \n",
       "1017119  http://images.amazon.com/images/P/0525447644.0...   \n",
       "1017120  http://images.amazon.com/images/P/006008667X.0...   \n",
       "1017121  http://images.amazon.com/images/P/0192126040.0...   \n",
       "1017122  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                               Image-URL-M  \\\n",
       "0        http://images.amazon.com/images/P/0195153448.0...   \n",
       "1        http://images.amazon.com/images/P/0002005018.0...   \n",
       "2        http://images.amazon.com/images/P/0002005018.0...   \n",
       "3        http://images.amazon.com/images/P/0002005018.0...   \n",
       "4        http://images.amazon.com/images/P/0002005018.0...   \n",
       "...                                                    ...   \n",
       "1017118  http://images.amazon.com/images/P/0440400988.0...   \n",
       "1017119  http://images.amazon.com/images/P/0525447644.0...   \n",
       "1017120  http://images.amazon.com/images/P/006008667X.0...   \n",
       "1017121  http://images.amazon.com/images/P/0192126040.0...   \n",
       "1017122  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                               Image-URL-L  User-ID  \\\n",
       "0        http://images.amazon.com/images/P/0195153448.0...        2   \n",
       "1        http://images.amazon.com/images/P/0002005018.0...        8   \n",
       "2        http://images.amazon.com/images/P/0002005018.0...    11400   \n",
       "3        http://images.amazon.com/images/P/0002005018.0...    11676   \n",
       "4        http://images.amazon.com/images/P/0002005018.0...    41385   \n",
       "...                                                    ...      ...   \n",
       "1017118  http://images.amazon.com/images/P/0440400988.0...   276463   \n",
       "1017119  http://images.amazon.com/images/P/0525447644.0...   276579   \n",
       "1017120  http://images.amazon.com/images/P/006008667X.0...   276680   \n",
       "1017121  http://images.amazon.com/images/P/0192126040.0...   276680   \n",
       "1017122  http://images.amazon.com/images/P/0767409752.0...   276680   \n",
       "\n",
       "         Book-Rating  \n",
       "0                  0  \n",
       "1                  5  \n",
       "2                  0  \n",
       "3                  8  \n",
       "4                  0  \n",
       "...              ...  \n",
       "1017118            7  \n",
       "1017119            4  \n",
       "1017120            0  \n",
       "1017121            0  \n",
       "1017122            0  \n",
       "\n",
       "[1017119 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df=ratings_df.dropna()\n",
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>11400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>11676</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>41385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017118</th>\n",
       "      <td>There's a Bat in Bunk Five</td>\n",
       "      <td>276463</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017119</th>\n",
       "      <td>From One to One Hundred</td>\n",
       "      <td>276579</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017120</th>\n",
       "      <td>Lily Dale : The True Story of the Town that Ta...</td>\n",
       "      <td>276680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017121</th>\n",
       "      <td>Republic (World's Classics)</td>\n",
       "      <td>276680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017122</th>\n",
       "      <td>A Guided Tour of Rene Descartes' Meditations o...</td>\n",
       "      <td>276680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1017119 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Book-Title  User-ID  \\\n",
       "0                                      Classical Mythology        2   \n",
       "1                                             Clara Callan        8   \n",
       "2                                             Clara Callan    11400   \n",
       "3                                             Clara Callan    11676   \n",
       "4                                             Clara Callan    41385   \n",
       "...                                                    ...      ...   \n",
       "1017118                         There's a Bat in Bunk Five   276463   \n",
       "1017119                            From One to One Hundred   276579   \n",
       "1017120  Lily Dale : The True Story of the Town that Ta...   276680   \n",
       "1017121                        Republic (World's Classics)   276680   \n",
       "1017122  A Guided Tour of Rene Descartes' Meditations o...   276680   \n",
       "\n",
       "         Book-Rating  \n",
       "0                  0  \n",
       "1                  5  \n",
       "2                  0  \n",
       "3                  8  \n",
       "4                  0  \n",
       "...              ...  \n",
       "1017118            7  \n",
       "1017119            4  \n",
       "1017120            0  \n",
       "1017121            0  \n",
       "1017122            0  \n",
       "\n",
       "[1017119 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete unnecessary columns\n",
    "ratings_df_adj=ratings_df.drop(['ISBN','Book-Author','Year-Of-Publication','Publisher','Image-URL-S','Image-URL-M','Image-URL-L'], axis=1)\n",
    "ratings_df_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter out data with zero ratings\n",
    "# ratings_df_adj = ratings_df_adj[ratings_df_adj['Book-Rating'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As an alternative to the above update 0 scores with weighted averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_weighted(row):\n",
    "    min_th=25 #min number of rating received by the book\n",
    "    neutral_score=5\n",
    "    avg_w = ((row['avg_book_rating'] * row['count_book_rating']) + \n",
    "      (min_th * neutral_score))/(row['count_book_rating'] + min_th)\n",
    "    return avg_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find average score per each book (only take non-zero into account)\n",
    "avg_ratings_scored = ratings_df[ratings_df['Book-Rating'] > 0].groupby('Book-Title')['Book-Rating'].mean()\n",
    "# count of non-zero rating given per book\n",
    "count_ratings_scored = ratings_df[ratings_df['Book-Rating'] > 0].groupby('Book-Title')['Book-Rating'].count()\n",
    "# create dataframe with above data (average and count) per book\n",
    "average_weighted_df=pd.DataFrame(avg_ratings_scored).rename(columns={'Book-Rating':'avg_book_rating'})\n",
    "count_ratings_scored_df=pd.DataFrame(count_ratings_scored).rename(columns={'Book-Rating':'count_book_rating'})\n",
    "average_weighted_df=pd.merge(average_weighted_df,count_ratings_scored_df,  on='Book-Title', how='inner')\n",
    "average_weighted_df=average_weighted_df.sort_values(by='count_book_rating', ascending=False)\n",
    "# find average weighted per book\n",
    "average_weighted_df['avg_weighted']=average_weighted_df.apply(average_weighted, axis=1)\n",
    "# update zero rating values with average weighted\n",
    "ratings_df_adj=ratings_df.copy()\n",
    "ratings_df_adj.loc[ratings_df_adj['Book-Rating'] == 0, 'Book-Rating'] = ratings_df_adj.loc[ratings_df_adj['Book-Rating'] == 0].index.map(average_weighted_df['avg_weighted'])\n",
    "# Filter out data with n/a rating score after mapping, as there could be books with only 0 scores\n",
    "ratings_df_adj=ratings_df_adj.dropna(subset=['Book-Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93704</th>\n",
       "      <td>0451524934</td>\n",
       "      <td>1984</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>1990</td>\n",
       "      <td>Signet Book</td>\n",
       "      <td>http://images.amazon.com/images/P/0451524934.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0451524934.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0451524934.0...</td>\n",
       "      <td>112083</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237681</th>\n",
       "      <td>0451519841</td>\n",
       "      <td>1984</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>1980</td>\n",
       "      <td>New Amer Library</td>\n",
       "      <td>http://images.amazon.com/images/P/0451519841.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0451519841.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0451519841.0...</td>\n",
       "      <td>112083</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85516</th>\n",
       "      <td>0446610038</td>\n",
       "      <td>1st to Die: A Novel</td>\n",
       "      <td>James Patterson</td>\n",
       "      <td>2002</td>\n",
       "      <td>Warner Vision</td>\n",
       "      <td>http://images.amazon.com/images/P/0446610038.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0446610038.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0446610038.0...</td>\n",
       "      <td>11676</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148791</th>\n",
       "      <td>0316666009</td>\n",
       "      <td>1st to Die: A Novel</td>\n",
       "      <td>James Patterson</td>\n",
       "      <td>2001</td>\n",
       "      <td>Little Brown and Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0316666009.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0316666009.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0316666009.0...</td>\n",
       "      <td>11676</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85683</th>\n",
       "      <td>0446610038</td>\n",
       "      <td>1st to Die: A Novel</td>\n",
       "      <td>James Patterson</td>\n",
       "      <td>2002</td>\n",
       "      <td>Warner Vision</td>\n",
       "      <td>http://images.amazon.com/images/P/0446610038.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0446610038.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0446610038.0...</td>\n",
       "      <td>143175</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789024</th>\n",
       "      <td>1569317674</td>\n",
       "      <td>Zoids Chaotic Century (Zoids: Chaotic Century ...</td>\n",
       "      <td>Michiro Ueyama</td>\n",
       "      <td>2002</td>\n",
       "      <td>Viz Comics</td>\n",
       "      <td>http://images.amazon.com/images/P/1569317674.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1569317674.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1569317674.0...</td>\n",
       "      <td>63714</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789027</th>\n",
       "      <td>1569317666</td>\n",
       "      <td>Zoids Chaotic Century (Zoids: Chaotic Century ...</td>\n",
       "      <td>Michiro Ueyama</td>\n",
       "      <td>2002</td>\n",
       "      <td>Viz Comics</td>\n",
       "      <td>http://images.amazon.com/images/P/1569317666.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1569317666.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1569317666.0...</td>\n",
       "      <td>63714</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789029</th>\n",
       "      <td>1569317658</td>\n",
       "      <td>Zoids Chaotic Century (Zoids: Chaotic Century ...</td>\n",
       "      <td>Michiro Ueyama</td>\n",
       "      <td>2002</td>\n",
       "      <td>Viz Comics</td>\n",
       "      <td>http://images.amazon.com/images/P/1569317658.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1569317658.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/1569317658.0...</td>\n",
       "      <td>63714</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404430</th>\n",
       "      <td>0440203856</td>\n",
       "      <td>Zoya</td>\n",
       "      <td>Danielle Steel</td>\n",
       "      <td>1989</td>\n",
       "      <td>Dell</td>\n",
       "      <td>http://images.amazon.com/images/P/0440203856.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440203856.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440203856.0...</td>\n",
       "      <td>62272</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474933</th>\n",
       "      <td>0385296495</td>\n",
       "      <td>Zoya</td>\n",
       "      <td>Danielle Steel</td>\n",
       "      <td>1988</td>\n",
       "      <td>Delacorte Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0385296495.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0385296495.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0385296495.0...</td>\n",
       "      <td>62272</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1915 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN                                         Book-Title  \\\n",
       "93704   0451524934                                               1984   \n",
       "237681  0451519841                                               1984   \n",
       "85516   0446610038                                1st to Die: A Novel   \n",
       "148791  0316666009                                1st to Die: A Novel   \n",
       "85683   0446610038                                1st to Die: A Novel   \n",
       "...            ...                                                ...   \n",
       "789024  1569317674  Zoids Chaotic Century (Zoids: Chaotic Century ...   \n",
       "789027  1569317666  Zoids Chaotic Century (Zoids: Chaotic Century ...   \n",
       "789029  1569317658  Zoids Chaotic Century (Zoids: Chaotic Century ...   \n",
       "404430  0440203856                                               Zoya   \n",
       "474933  0385296495                                               Zoya   \n",
       "\n",
       "            Book-Author  Year-Of-Publication                 Publisher  \\\n",
       "93704     George Orwell                 1990               Signet Book   \n",
       "237681    George Orwell                 1980          New Amer Library   \n",
       "85516   James Patterson                 2002             Warner Vision   \n",
       "148791  James Patterson                 2001  Little Brown and Company   \n",
       "85683   James Patterson                 2002             Warner Vision   \n",
       "...                 ...                  ...                       ...   \n",
       "789024   Michiro Ueyama                 2002                Viz Comics   \n",
       "789027   Michiro Ueyama                 2002                Viz Comics   \n",
       "789029   Michiro Ueyama                 2002                Viz Comics   \n",
       "404430   Danielle Steel                 1989                      Dell   \n",
       "474933   Danielle Steel                 1988           Delacorte Press   \n",
       "\n",
       "                                              Image-URL-S  \\\n",
       "93704   http://images.amazon.com/images/P/0451524934.0...   \n",
       "237681  http://images.amazon.com/images/P/0451519841.0...   \n",
       "85516   http://images.amazon.com/images/P/0446610038.0...   \n",
       "148791  http://images.amazon.com/images/P/0316666009.0...   \n",
       "85683   http://images.amazon.com/images/P/0446610038.0...   \n",
       "...                                                   ...   \n",
       "789024  http://images.amazon.com/images/P/1569317674.0...   \n",
       "789027  http://images.amazon.com/images/P/1569317666.0...   \n",
       "789029  http://images.amazon.com/images/P/1569317658.0...   \n",
       "404430  http://images.amazon.com/images/P/0440203856.0...   \n",
       "474933  http://images.amazon.com/images/P/0385296495.0...   \n",
       "\n",
       "                                              Image-URL-M  \\\n",
       "93704   http://images.amazon.com/images/P/0451524934.0...   \n",
       "237681  http://images.amazon.com/images/P/0451519841.0...   \n",
       "85516   http://images.amazon.com/images/P/0446610038.0...   \n",
       "148791  http://images.amazon.com/images/P/0316666009.0...   \n",
       "85683   http://images.amazon.com/images/P/0446610038.0...   \n",
       "...                                                   ...   \n",
       "789024  http://images.amazon.com/images/P/1569317674.0...   \n",
       "789027  http://images.amazon.com/images/P/1569317666.0...   \n",
       "789029  http://images.amazon.com/images/P/1569317658.0...   \n",
       "404430  http://images.amazon.com/images/P/0440203856.0...   \n",
       "474933  http://images.amazon.com/images/P/0385296495.0...   \n",
       "\n",
       "                                              Image-URL-L  User-ID  \\\n",
       "93704   http://images.amazon.com/images/P/0451524934.0...   112083   \n",
       "237681  http://images.amazon.com/images/P/0451519841.0...   112083   \n",
       "85516   http://images.amazon.com/images/P/0446610038.0...    11676   \n",
       "148791  http://images.amazon.com/images/P/0316666009.0...    11676   \n",
       "85683   http://images.amazon.com/images/P/0446610038.0...   143175   \n",
       "...                                                   ...      ...   \n",
       "789024  http://images.amazon.com/images/P/1569317674.0...    63714   \n",
       "789027  http://images.amazon.com/images/P/1569317666.0...    63714   \n",
       "789029  http://images.amazon.com/images/P/1569317658.0...    63714   \n",
       "404430  http://images.amazon.com/images/P/0440203856.0...    62272   \n",
       "474933  http://images.amazon.com/images/P/0385296495.0...    62272   \n",
       "\n",
       "        Book-Rating  \n",
       "93704           9.0  \n",
       "237681          9.0  \n",
       "85516          10.0  \n",
       "148791          8.0  \n",
       "85683          10.0  \n",
       "...             ...  \n",
       "789024         10.0  \n",
       "789027         10.0  \n",
       "789029         10.0  \n",
       "404430          9.0  \n",
       "474933          9.0  \n",
       "\n",
       "[1915 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are duplicated records when same user rated book(s) with same title several times\n",
    "ratings_df_adj[ratings_df_adj.duplicated(subset=['Book-Title', 'User-ID'],keep=False)].sort_values(by=['Book-Title','User-ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Storm: The Civil War Diary of ...</td>\n",
       "      <td>96448</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ask Lily (Young Women of Faith: Lily Series, ...</td>\n",
       "      <td>269557</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dark Justice</td>\n",
       "      <td>98391</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Earth Prayers From around the World: 365 Pray...</td>\n",
       "      <td>26544</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earth Prayers From around the World: 365 Pray...</td>\n",
       "      <td>69120</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377056</th>\n",
       "      <td>Ã?Â?rger mit Produkt X. Roman.</td>\n",
       "      <td>133567</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377057</th>\n",
       "      <td>Ã?Â?rger mit Produkt X. Roman.</td>\n",
       "      <td>225343</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377058</th>\n",
       "      <td>Ã?Â?sterlich leben.</td>\n",
       "      <td>256636</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377059</th>\n",
       "      <td>Ã?Â?stlich der Berge.</td>\n",
       "      <td>90839</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377060</th>\n",
       "      <td>Ã?Â?thique en toc</td>\n",
       "      <td>25436</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>377061 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Book-Title  User-ID  \\\n",
       "0        A Light in the Storm: The Civil War Diary of ...    96448   \n",
       "1        Ask Lily (Young Women of Faith: Lily Series, ...   269557   \n",
       "2                                            Dark Justice    98391   \n",
       "3        Earth Prayers From around the World: 365 Pray...    26544   \n",
       "4        Earth Prayers From around the World: 365 Pray...    69120   \n",
       "...                                                   ...      ...   \n",
       "377056                     Ã?Â?rger mit Produkt X. Roman.   133567   \n",
       "377057                     Ã?Â?rger mit Produkt X. Roman.   225343   \n",
       "377058                                Ã?Â?sterlich leben.   256636   \n",
       "377059                              Ã?Â?stlich der Berge.    90839   \n",
       "377060                                  Ã?Â?thique en toc    25436   \n",
       "\n",
       "        Book-Rating  \n",
       "0               9.0  \n",
       "1               8.0  \n",
       "2              10.0  \n",
       "3               9.0  \n",
       "4              10.0  \n",
       "...             ...  \n",
       "377056          8.0  \n",
       "377057          7.0  \n",
       "377058          7.0  \n",
       "377059          8.0  \n",
       "377060          8.0  \n",
       "\n",
       "[377061 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use avg rate per duplicates set\n",
    "ratings_df_adj=ratings_df_adj.groupby(['Book-Title','User-ID'])['Book-Rating'].mean().reset_index()\n",
    "ratings_df_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only leave statistically signifacant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define whar are the number of rates per book and books rated by user we treat as statistically significant\n",
    "min_books_rated_by_user=5\n",
    "min_rates_received_by_book=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User-ID\n",
       "8     7\n",
       "9     1\n",
       "12    1\n",
       "14    3\n",
       "16    1\n",
       "Name: Book-Rating, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupped_r_users=ratings_df_adj.groupby('User-ID')['Book-Rating'].count()\n",
    "groupped_r_users[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Book-Title\n",
       " A Light in the Storm: The Civil War Diary of Amelia Martin, Fenwick Island, Delaware, 1861 (Dear America)    1\n",
       " Ask Lily (Young Women of Faith: Lily Series, Book 5)                                                         1\n",
       " Dark Justice                                                                                                 1\n",
       " Earth Prayers From around the World: 365 Prayers, Poems, and Invocations for Honoring the Earth              7\n",
       " Final Fantasy Anthology: Official Strategy Guide (Brady Games)                                               2\n",
       "Name: User-ID, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupped_r_books=ratings_df_adj.groupby('Book-Title')['User-ID'].count()\n",
    "groupped_r_books[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Earth Prayers From around the World: 365 Prayers, Poems, and Invocations for Honoring the Earth',\n",
       " '!Yo!',\n",
       " \"'Salem's Lot\",\n",
       " '01-01-00: The Novel of the Millennium',\n",
       " '10 Lb. Penalty']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select only those books which were rated more than min_rates_received_by_book\n",
    "titles_with_acceptable_rates_count=list(groupped_r_books[groupped_r_books>min_rates_received_by_book].index)\n",
    "titles_with_acceptable_rates_count[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 99, 114, 242, 243]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select only those users (user_id) who rated more than min_books_rated_by_user books\n",
    "user_ids_with_acceptable_books_count_rated=list(groupped_r_users[groupped_r_users>min_books_rated_by_user].index)\n",
    "user_ids_with_acceptable_books_count_rated[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Earth Prayers From around the World: 365 Pray...</td>\n",
       "      <td>26544</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Earth Prayers From around the World: 365 Pray...</td>\n",
       "      <td>121592</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Earth Prayers From around the World: 365 Pray...</td>\n",
       "      <td>179730</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Earth Prayers From around the World: 365 Pray...</td>\n",
       "      <td>179744</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Earth Prayers From around the World: 365 Pray...</td>\n",
       "      <td>205980</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376999</th>\n",
       "      <td>stardust</td>\n",
       "      <td>274393</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377020</th>\n",
       "      <td>why I'm like this : True Stories</td>\n",
       "      <td>36609</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377021</th>\n",
       "      <td>why I'm like this : True Stories</td>\n",
       "      <td>98904</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377022</th>\n",
       "      <td>why I'm like this : True Stories</td>\n",
       "      <td>105317</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377023</th>\n",
       "      <td>why I'm like this : True Stories</td>\n",
       "      <td>158254</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140610 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Book-Title  User-ID  \\\n",
       "3        Earth Prayers From around the World: 365 Pray...    26544   \n",
       "5        Earth Prayers From around the World: 365 Pray...   121592   \n",
       "6        Earth Prayers From around the World: 365 Pray...   179730   \n",
       "7        Earth Prayers From around the World: 365 Pray...   179744   \n",
       "8        Earth Prayers From around the World: 365 Pray...   205980   \n",
       "...                                                   ...      ...   \n",
       "376999                                           stardust   274393   \n",
       "377020                   why I'm like this : True Stories    36609   \n",
       "377021                   why I'm like this : True Stories    98904   \n",
       "377022                   why I'm like this : True Stories   105317   \n",
       "377023                   why I'm like this : True Stories   158254   \n",
       "\n",
       "        Book-Rating  \n",
       "3               9.0  \n",
       "5               7.0  \n",
       "6               1.0  \n",
       "7               6.0  \n",
       "8              10.0  \n",
       "...             ...  \n",
       "376999          8.0  \n",
       "377020          6.0  \n",
       "377021         10.0  \n",
       "377022          8.0  \n",
       "377023          6.0  \n",
       "\n",
       "[140610 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter rating-user data to have only books/users of interest (which have highest rates count and rated highest number of books respectively)\n",
    "rating_final_df=ratings_df_adj[ratings_df_adj['Book-Title'].isin(titles_with_acceptable_rates_count)&ratings_df_adj['User-ID'].isin(user_ids_with_acceptable_books_count_rated)]\n",
    "rating_final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure SVD model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in such a ways that we have data for all the users in both train and test sets\n",
    "user_list = rating_final_df['User-ID'].unique() #list of all users\n",
    "test_set = pd.DataFrame(columns=rating_final_df.columns) # reserve df for a train set\n",
    "train_set = pd.DataFrame(columns=rating_final_df.columns) # reserve df for a test set\n",
    "test_ratio = 0.1 # we would have 10% test data\n",
    "for user in user_list:\n",
    "    # for each user take their book/rating data \n",
    "    user_data_all = rating_final_df[rating_final_df['User-ID'] == user]\n",
    "    n = len(user_data_all)\n",
    "    user_data_all = user_data_all.reset_index()\n",
    "    user_data_all.drop('index', axis=1, inplace=True)\n",
    "    # split user data into train and test \n",
    "    test_size = int(test_ratio*n)\n",
    "    \n",
    "    # randomly select roughtly 10% of rows for test set per user using random_state=1, so that result is reproducible\n",
    "    test = user_data_all.sample(n=test_size, random_state=1)  \n",
    "\n",
    "    # rows not selected for test set, assigned to train one\n",
    "    train = user_data_all.drop(test.index)\n",
    "\n",
    "    test_set = pd.concat([test_set, test], ignore_index=True)\n",
    "    train_set = pd.concat([train_set, train], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prediction_matrix(rating_input_df, latent_factors=70):\n",
    "## Build the model  \n",
    "    # Pivot to obtain a matrix that stores original ratings given by users for books and fill sparse values with 0-s\n",
    "    df_books_ratigs_user=rating_input_df.pivot_table(index='User-ID', columns='Book-Title', values='Book-Rating').fillna(0)\n",
    "    # Normilize the data, using mean normalization.\n",
    "    data_original = df_books_ratigs_user.to_numpy() # vectorize the data\n",
    "    ratings_mean = np.mean(data_original, axis = 1) # find a mean per each vector (user)\n",
    "    normalized_data = data_original - ratings_mean.reshape(-1, 1) #subtract mean for each user from their ratings, which centers the ratings around 0 for each user\n",
    "    # Decompose the normilized matrix into 3, with k = latent_factors (70 default) largest singular values in sigma\n",
    "    U, sigma, Vt = svds(normalized_data, k = latent_factors)\n",
    "    # Convert vector to a diagonal matrix\n",
    "    sigma = np.diag(sigma)\n",
    "    # Compose matrix with predictions, reversing data normalization\n",
    "    all_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + ratings_mean.reshape(-1, 1)\n",
    "    # convert numpy array into dataframe\n",
    "    all_predictions_df = pd.DataFrame(all_predicted_ratings, columns=df_books_ratigs_user.columns)\n",
    "    # add a colmns with user id, so that we can filter data by it\n",
    "    all_predictions_df['user_id'] = df_books_ratigs_user.index\n",
    "    return all_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books_for_user_svd (user_id, all_predictions_df, ratings_df, books_df, recommendations_count=5):\n",
    "## Find prediction for a specific user\n",
    "    # find the books (titles) that were rated and presumably read by a user\n",
    "    rated_titles=[i for i in ratings_df.loc[ratings_df['User-ID']==user_id,'Book-Title']]\n",
    "    titles_to_exclude=rated_titles\n",
    "    # find all the titles within the matrix\n",
    "    all_titles=all_predictions_df.columns[:-1]\n",
    "    # separate those titles that were not read\n",
    "    titles_input_to_recommend=[i for i in all_titles if i not in titles_to_exclude]\n",
    "    # find predictions for a user\n",
    "    user_predictions_all=all_predictions_df.loc[all_predictions_df['user_id']==user_id]\n",
    "    # sort predictions and select top recommendations_count\n",
    "    col_name=user_predictions_all.loc[user_predictions_all['user_id']==user_id].index[0]\n",
    "    user_recommendation=user_predictions_all.T\n",
    "    user_recommendation=user_recommendation.loc[titles_input_to_recommend].sort_values(by=col_name, ascending=False)\n",
    "    top_recommendations=user_recommendation[:recommendations_count].rename(columns={col_name:'estimated rate'})\n",
    "    # populate books with full info, selecting those books with the most recent year of publication\n",
    "    recommendations_full_info=pd.merge(top_recommendations, books_df, left_on='Book-Title',right_on='Book-Title', how='left')\n",
    "    dict_years=dict(recommendations_full_info.groupby('Book-Title')['Year-Of-Publication'].max())\n",
    "    for i, row in recommendations_full_info.iterrows():\n",
    "        if row['Year-Of-Publication']!=dict_years[row['Book-Title']]:\n",
    "            recommendations_full_info.loc[i,'Year-Of-Publication']=0\n",
    "    recommendations_full_info=recommendations_full_info[recommendations_full_info['Year-Of-Publication'] != 0]\n",
    "    recommendations_full_info=recommendations_full_info.drop_duplicates(subset=['Book-Title'])\n",
    "    return recommendations_full_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_predictions_df=build_prediction_matrix(rating_final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define formula for calculation of rmse\n",
    "def rmse(true, pred):\n",
    "    error = true - pred\n",
    "    mean_square_error=sum([i*i for i in error])/len(error)\n",
    "    return math.sqrt(mean_square_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8: 7.810468546894521,\n",
       " 20: 7.773952750654797,\n",
       " 50: 7.740889009963508,\n",
       " 100: 7.747020695731257,\n",
       " 150: 7.76868039500691}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to test the performance over a different number of laatent factors\n",
    "k_set = [8, 20, 50, 100, 150]\n",
    "rmse_scores={}\n",
    "for l_f in k_set: \n",
    "    # Build the prediction matrix using the train_set\n",
    "    all_predictions_df = build_prediction_matrix(train_set, l_f)\n",
    "\n",
    "    # reserve a list for predicted ratings\n",
    "    pred = []\n",
    "    for i, row in test_set.iterrows():\n",
    "        user_id = row['User-ID']\n",
    "        book_title = row['Book-Title']  \n",
    "        if user_id in all_predictions_df['user_id'].values and book_title in all_predictions_df.columns[:-1]:\n",
    "            pred_rating = all_predictions_df.loc[all_predictions_df['user_id'] == user_id, book_title].values[0]\n",
    "        else:\n",
    "            # If the book or user is not in the train_set, use a default prediction\n",
    "            # which is the average of all ratings in the training set as a simple approach\n",
    "            pred_rating = train_set['Book-Rating'].mean()   \n",
    "        pred.append(pred_rating)\n",
    "    \n",
    "    # Calculate RMSE for the current number of features\n",
    "    current_rmse = rmse(test_set['Book-Rating'], pred)\n",
    "    rmse_scores[l_f]=current_rmse\n",
    "rmse_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD Funk\n",
    "Use of surprise module with built-in SVD algorithm (popularized by Simon Funk during the Netflix Prize):\n",
    "\n",
    "class surprise.prediction_algorithms.matrix_factorization.SVD(n_factors=100, n_epochs=20, biased=True, init_mean=0, init_std_dev=0.1, lr_all=0.005, reg_all=0.02, lr_bu=None, lr_bi=None, lr_pu=None, lr_qi=None, reg_bu=None, reg_bi=None, reg_pu=None, reg_qi=None, random_state=None, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for parsing by 'surprise algorithms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even having dataframe we need to create a 'reader' with the 'rating_scale' parameter to let know that our dataset has ratings from 1 to 10\n",
    "# https://surprise.readthedocs.io/en/stable/getting_started.html#load-custom\n",
    "reader = Reader(rating_scale=(1,10))\n",
    "\n",
    "# and create respective surprise.dataset object, so that our data are in a proper format for the recommendation algorithms\n",
    "data_surprise_o = Dataset.load_from_df(rating_final_df[['User-ID','Book-Title','Book-Rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'------Train Set------'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train_set: 112488\n",
      "Number of users in train_set: 10199\n",
      "Number of books in train_set: 10619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Few elements of train_set (user, book, rating): [(0, 0, 8.0), (0, 80, 7.0), (0, 837, 10.0), (0, 1074, 9.0), (0, 3718, 8.0), (0, 4298, 9.0), (0, 259, 7.0), (0, 78, 10.0), (0, 543, 9.0), (0, 6729, 10.0), (0, 1097, 10.0), (0, 3635, 9.0), (0, 1484, 9.0), (0, 5195, 8.0), (0, 1574, 9.0)]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'------Test Set------'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test_set: 28122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Few elements of test_set (user, book, rating): [(92405, \"Night\\'s Landing (Mira)\", 8.0), (265889, \\'Out of Control\\', 8.0), (27313, \\'A Walk to Remember\\', 9.0), (23571, \\'The Two Towers (The Lord of the Rings, Part 2)\\', 10.0), (170724, \\'Lone Eagle\\', 5.0), (95359, \\'AGE OF INNOCENCE (MOVIE TIE-IN)\\', 10.0), (158295, \\'Prime Witness\\', 6.0), (263078, \\'Wild Animus\\', 2.0), (27140, \\'DAUGHTER OF TIME\\', 10.0), (276925, \\'La Sombra del Viento\\', 10.0), (234953, \\'Primary Colors: A Novel of Politics\\', 7.0), (204802, \\'Round Robin: An Elm Creek Quilts Novel (Elm Creek Quilters Novels)\\', 8.0), (126814, \\'The Cat Who Blew the Whistle\\', 7.0), (145109, \\'The Drawing of the Three (The Dark Tower, Book 2)\\', 9.0), (98741, \"Suzanne\\'s Diary for Nicholas\", 7.0)]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split our data into train and test in ratio 8:2, using random_state = 42 so that we receive reproducable output\n",
    "random_state = 42\n",
    "\n",
    "# Reference: https://surprise.readthedocs.io/en/stable/getting_started.html?highlight=train_test_split#train-test-split-and-the-fit-method\n",
    "\n",
    "train_set, test_set = train_test_split(data_surprise_o, test_size=0.2, shuffle=True, random_state=random_state)\n",
    "\n",
    "# check train and test data\n",
    "train_data = list(train_set.all_ratings())\n",
    "\n",
    "display('------Train Set------')\n",
    "print(f'Size of train_set: {len(train_data)}')\n",
    "print(f'Number of users in train_set: {train_set.n_users}')\n",
    "print(f'Number of books in train_set: {train_set.n_items}')\n",
    "display(f'Few elements of train_set (user, book, rating): {train_data[:15]}')\n",
    "display('------Test Set------')\n",
    "print(f'Size of test_set: {len(test_set)}')\n",
    "display(f'Few elements of test_set (user, book, rating): {test_set[:15]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training: cross validate the model\n",
    "Make preliminary estimation of error in predictions using RMSE metric for SVD Funk model and the whole set of data split into 5 folds to verify there is no overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "RMSE: 1.5961\n",
      "Estimating biases using als...\n",
      "RMSE: 1.5709\n",
      "Estimating biases using als...\n",
      "RMSE: 1.5745\n",
      "Estimating biases using als...\n",
      "RMSE: 1.5783\n",
      "Estimating biases using als...\n",
      "RMSE: 1.5620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Average Root Mean Square Error (RMSE) for BaselineOnly is 1.58'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.5918\n",
      "RMSE: 1.5672\n",
      "RMSE: 1.5719\n",
      "RMSE: 1.5752\n",
      "RMSE: 1.5565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Average Root Mean Square Error (RMSE) for SVD is 1.57'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reference: https://surprise.readthedocs.io/en/stable/getting_started.html?highlight=cross_validate#use-cross-validation-iterators\n",
    "\n",
    "# define number of subsets the dataset will be partitioned for cross validations\n",
    "folds_n=5\n",
    "\n",
    "# define a cross-validation iterator\n",
    "kf = KFold(n_splits=folds_n,random_state=42)\n",
    "algo = [BaselineOnly(),SVD()]\n",
    "for i in algo:\n",
    "    mean_rmse=[]\n",
    "    for trainset, testset in kf.split(data_surprise_o):\n",
    "        # train and test algorithm.\n",
    "        i.fit(trainset)\n",
    "        predictions = i.test(testset)\n",
    "        # Compute and print Root Mean Squared Error\n",
    "        mean_rmse.append(accuracy.rmse(predictions))\n",
    "    # Find an average rmse for all the folds\n",
    "    mean_rmse=st.mean(mean_rmse)\n",
    "    display(f'Average Root Mean Square Error (RMSE) for {i.__class__.__name__} is {round(mean_rmse,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training: identify best parameters¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSearchCV(SVD, param_grid, measures\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m], cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# train the model for all the combinations of parameters\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m gs\u001b[38;5;241m.\u001b[39mfit(data_surprise_o)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# select the set of parameters that produce lowest value for rmse metric\u001b[39;00m\n\u001b[1;32m     20\u001b[0m params \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/surprise/model_selection/search.py:104\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     90\u001b[0m cv \u001b[38;5;241m=\u001b[39m get_cv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv)\n\u001b[1;32m     92\u001b[0m delayed_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     93\u001b[0m     delayed(fit_and_score)(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgo_class(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m     )\n\u001b[1;32m    103\u001b[0m )\n\u001b[0;32m--> 104\u001b[0m out \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    105\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    106\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_dispatch,\n\u001b[1;32m    107\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoblib_verbose,\n\u001b[1;32m    108\u001b[0m )(delayed_list)\n\u001b[1;32m    110\u001b[0m (test_measures_dicts, train_measures_dicts, fit_times, test_times) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mout)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# test_measures_dicts is a list of dict like this:\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# [{'mae': 1, 'rmse': 2}, {'mae': 2, 'rmse': 3} ...]\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# E.g. for 5 splits, the first 5 dicts are for the first param\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# (n_parameters_combinations, n_splits). This way we can easily compute\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# the mean and std dev over all splits or over all param comb.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/surprise/model_selection/validation.py:176\u001b[0m, in \u001b[0;36mfit_and_score\u001b[0;34m(algo, trainset, testset, measures, return_train_measures)\u001b[0m\n\u001b[1;32m    174\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_fit\n\u001b[1;32m    175\u001b[0m start_test \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 176\u001b[0m predictions \u001b[38;5;241m=\u001b[39m algo\u001b[38;5;241m.\u001b[39mtest(testset)\n\u001b[1;32m    177\u001b[0m test_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_test\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_measures:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/surprise/prediction_algorithms/algo_base.py:160\u001b[0m, in \u001b[0;36mAlgoBase.test\u001b[0;34m(self, testset, verbose)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test the algorithm on given testset, i.e. estimate all the ratings\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03min the given testset.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    that contains all the estimated ratings.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# The ratings are translated back to their original scale.\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(uid, iid, r_ui_trans, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (uid, iid, r_ui_trans) \u001b[38;5;129;01min\u001b[39;00m testset\n\u001b[1;32m    163\u001b[0m ]\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/surprise/prediction_algorithms/algo_base.py:161\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test the algorithm on given testset, i.e. estimate all the ratings\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03min the given testset.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    that contains all the estimated ratings.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# The ratings are translated back to their original scale.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(uid, iid, r_ui_trans, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (uid, iid, r_ui_trans) \u001b[38;5;129;01min\u001b[39;00m testset\n\u001b[1;32m    163\u001b[0m ]\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/surprise/prediction_algorithms/algo_base.py:118\u001b[0m, in \u001b[0;36mAlgoBase.predict\u001b[0;34m(self, uid, iid, r_ui, clip, verbose)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clip:\n\u001b[1;32m    117\u001b[0m     lower_bound, higher_bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainset\u001b[38;5;241m.\u001b[39mrating_scale\n\u001b[0;32m--> 118\u001b[0m     est \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(higher_bound, est)\n\u001b[1;32m    119\u001b[0m     est \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(lower_bound, est)\n\u001b[1;32m    121\u001b[0m pred \u001b[38;5;241m=\u001b[39m Prediction(uid, iid, r_ui, est, details)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# reference: https://medium.com/p/61c269402919\n",
    "# within the dictionary param_grid set ranges for parameters to try out, where \n",
    "#  - key: parameter name, \n",
    "#  - value:  list of parameter values to try\n",
    "param_grid = {'n_factors':[10,20,50,100,150], 'n_epochs':[10,20,30,50,100], 'lr_all':[0.002,0.005,0.01,0.3],'reg_all':[0.02, 0.1, 0.2]}\n",
    "# n_factors - number of latent factors (Default is 100)\n",
    "# n_epochs - number of iterations (Default is 20)\n",
    "# lr_all - step size for the gradient descent optimization (learning rate, Default is 0.005)\n",
    "# reg_all -  regularization term for all parameter, used to prevent overfitting (Default is 0.02)\n",
    "\n",
    "# Select parameters for our SVD algorithm by cross validation and looking for rmse metric\n",
    "# GridSearchCV() calculates a score for each combination of hyperparameters on a k-fold cross validated dataset \n",
    "# and returns the set of parameters that minimises the mean score across folds\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=5)\n",
    "\n",
    "# train the model for all the combinations of parameters\n",
    "gs.fit(data_surprise_o)\n",
    "\n",
    "# select the set of parameters that produce lowest value for rmse metric\n",
    "params = gs.best_params['rmse']\n",
    "params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training: Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SVD with default parameters\n",
    "svd_default = SVD()\n",
    "# Build SVD, using hyperparameters recevied in the result of hypertuning\n",
    "svd_best_parameters = SVD(n_factors=params['n_factors'], n_epochs=params['n_epochs'],lr_all=params['lr_all'], reg_all=params['reg_all'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training: Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models on trainset\n",
    "svd_best_parameters_model = svd_best_parameters.fit(train_set)\n",
    "svd_default_model = svd_default.fit(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books_for_user_svd_funk (user_id, model, ratings_df_adj, books_df, recommendations_count=5):\n",
    "    # find all the books (titles)\n",
    "    all_titles=ratings_df_adj['Book-Title'].unique()\n",
    "    # find the books (titles) that were rated and presumably read by a user\n",
    "    rated_titles=[i for i in ratings_df_adj.loc[ratings_df_adj['User-ID']==user_id,'Book-Title']]\n",
    "    # find the books (titles) that were not rated and presumably not read by a user\n",
    "    titles_input_to_recommend=[i for i in all_titles if i not in rated_titles]\n",
    "    # find predictions for a user\n",
    "        # reference: https://surprise.readthedocs.io/en/stable/algobase.html?highlight=predict\n",
    "        # uid – (Raw) id of the user. \n",
    "        # iid – (Raw) id of the item.\n",
    "        # verbose (bool) – Whether to print details of the prediction. Default is False.\n",
    "    predictions=[model.predict(uid=user_id, iid=i) for i in titles_input_to_recommend]\n",
    "    # get ratings estimate for books by the user\n",
    "    ratings=[i.est for i in predictions]\n",
    "    # convert predicted estimates by the user for not read books into df\n",
    "    pred_dict={\n",
    "        'Book-Title':titles_input_to_recommend,\n",
    "        'Estimated_Rate':ratings}\n",
    "    predictions_book=pd.DataFrame(pred_dict).sort_values('Estimated_Rate',ascending = False)\n",
    "    top_recommendations=predictions_book.head(recommendations_count)\n",
    "    # populate books with full info, selecting those books with the most recent year of publication\n",
    "    recommendations_full_info=pd.merge(top_recommendations, books_df, left_on='Book-Title',right_on='Book-Title', how='left')\n",
    "    dict_years=dict(recommendations_full_info.groupby('Book-Title')['Year-Of-Publication'].max())\n",
    "    for i, row in recommendations_full_info.iterrows():\n",
    "        if row['Year-Of-Publication']!=dict_years[row['Book-Title']]:\n",
    "            recommendations_full_info.loc[i,'Year-Of-Publication']=0\n",
    "    recommendations_full_info=recommendations_full_info[recommendations_full_info['Year-Of-Publication'] != 0]\n",
    "    recommendations_full_info=recommendations_full_info.drop_duplicates(subset=['Book-Title'])\n",
    "    return recommendations_full_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, based on Root Mean Square Error, of a Model with Default Parameters:\n",
      "1.556558929422831\n"
     ]
    }
   ],
   "source": [
    "# Check the accuracy for both default vs tuned method\n",
    "print(f'''Accuracy, based on Root Mean Square Error, of a Tuned Model: \n",
    "{accuracy.rmse(svd_best_parameters_model.test(test_set), verbose=False)}''')\n",
    "\n",
    "print(f'''Accuracy, based on Root Mean Square Error, of a Model with Default Parameters:\n",
    "{accuracy.rmse(svd_default_model.test(test_set), verbose=False)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy, based on Mean Absolute Error, of a Model with Default Parameters:\n",
      "1.1979634086673705\n"
     ]
    }
   ],
   "source": [
    "print(f'''Accuracy, based on Mean Absolute Error, of a Model with Default Parameters:\n",
    "{accuracy.mae(svd_default_model.test(test_set), verbose=False)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check predictions for specific user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1016791</th>\n",
       "      <td>252676</td>\n",
       "      <td>The Twelve Days of Christmas</td>\n",
       "      <td>10</td>\n",
       "      <td>Anne Geddes</td>\n",
       "      <td>1997</td>\n",
       "      <td>Cedco Publishing Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016789</th>\n",
       "      <td>252676</td>\n",
       "      <td>The Flavors of Bon Appetit 1997 (Bon Appetit ,...</td>\n",
       "      <td>8</td>\n",
       "      <td>Editors of Bon Appetit</td>\n",
       "      <td>1997</td>\n",
       "      <td>Pantheon Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533707</th>\n",
       "      <td>252676</td>\n",
       "      <td>The Importance of Being Earnest: A Trivial Nov...</td>\n",
       "      <td>8</td>\n",
       "      <td>Charles Osborne</td>\n",
       "      <td>2000</td>\n",
       "      <td>St Martins Pr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016788</th>\n",
       "      <td>252676</td>\n",
       "      <td>Lilith's Cave: Jewish Tales of the Supernatural</td>\n",
       "      <td>7</td>\n",
       "      <td>Howard Schwartz</td>\n",
       "      <td>1988</td>\n",
       "      <td>Harpercollins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83181</th>\n",
       "      <td>252676</td>\n",
       "      <td>The Brethren</td>\n",
       "      <td>7</td>\n",
       "      <td>John Grisham</td>\n",
       "      <td>2000</td>\n",
       "      <td>Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957473</th>\n",
       "      <td>252676</td>\n",
       "      <td>The Devil's Cat</td>\n",
       "      <td>6</td>\n",
       "      <td>William W. Johnstone</td>\n",
       "      <td>1987</td>\n",
       "      <td>Zebra Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182440</th>\n",
       "      <td>252676</td>\n",
       "      <td>Hideaway</td>\n",
       "      <td>5</td>\n",
       "      <td>Dean R. Koontz</td>\n",
       "      <td>1992</td>\n",
       "      <td>Berkley Publishing Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42777</th>\n",
       "      <td>252676</td>\n",
       "      <td>Skipping Christmas</td>\n",
       "      <td>0</td>\n",
       "      <td>JOHN GRISHAM</td>\n",
       "      <td>2001</td>\n",
       "      <td>Doubleday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740036</th>\n",
       "      <td>252676</td>\n",
       "      <td>Vespers</td>\n",
       "      <td>0</td>\n",
       "      <td>Jeff Rovin</td>\n",
       "      <td>1999</td>\n",
       "      <td>St. Martin's Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016790</th>\n",
       "      <td>252676</td>\n",
       "      <td>The Best of Gourmet 1997 (Best of Gourmet, 1997)</td>\n",
       "      <td>0</td>\n",
       "      <td>The Editors of Gourmet</td>\n",
       "      <td>1997</td>\n",
       "      <td>Random House Trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794850</th>\n",
       "      <td>252676</td>\n",
       "      <td>Eat More, Weigh Less: Dr. Dean Ornish's Life C...</td>\n",
       "      <td>0</td>\n",
       "      <td>Dean Ornish</td>\n",
       "      <td>1997</td>\n",
       "      <td>HarperTorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687193</th>\n",
       "      <td>252676</td>\n",
       "      <td>Friendship Gifts of Good Taste</td>\n",
       "      <td>0</td>\n",
       "      <td>Anne Young</td>\n",
       "      <td>1992</td>\n",
       "      <td>Leisure Arts Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705809</th>\n",
       "      <td>252676</td>\n",
       "      <td>Three Complete Novels: Patriot Games, Clear an...</td>\n",
       "      <td>0</td>\n",
       "      <td>Tom Clancy</td>\n",
       "      <td>1994</td>\n",
       "      <td>Putnam Publishing Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410565</th>\n",
       "      <td>252676</td>\n",
       "      <td>Dragonsdawn</td>\n",
       "      <td>0</td>\n",
       "      <td>Anne McCaffrey</td>\n",
       "      <td>1989</td>\n",
       "      <td>Del Rey Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329664</th>\n",
       "      <td>252676</td>\n",
       "      <td>Another Fine Myth</td>\n",
       "      <td>0</td>\n",
       "      <td>Robert Asprin</td>\n",
       "      <td>1991</td>\n",
       "      <td>Ace Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292428</th>\n",
       "      <td>252676</td>\n",
       "      <td>The Attorney</td>\n",
       "      <td>0</td>\n",
       "      <td>Steve Martini</td>\n",
       "      <td>2001</td>\n",
       "      <td>Jove Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258015</th>\n",
       "      <td>252676</td>\n",
       "      <td>Bitter Harvest</td>\n",
       "      <td>0</td>\n",
       "      <td>Ann Rule</td>\n",
       "      <td>1999</td>\n",
       "      <td>Pocket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121960</th>\n",
       "      <td>252676</td>\n",
       "      <td>Don't Sweat the Small Stuff and It's All Small...</td>\n",
       "      <td>0</td>\n",
       "      <td>Richard Carlson</td>\n",
       "      <td>1997</td>\n",
       "      <td>Hyperion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016792</th>\n",
       "      <td>252676</td>\n",
       "      <td>Treasury of Campbell's Recipes</td>\n",
       "      <td>0</td>\n",
       "      <td>Campbell Soup Company</td>\n",
       "      <td>1991</td>\n",
       "      <td>Publications International</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         User-ID                                         Book-Title  \\\n",
       "1016791   252676                       The Twelve Days of Christmas   \n",
       "1016789   252676  The Flavors of Bon Appetit 1997 (Bon Appetit ,...   \n",
       "533707    252676  The Importance of Being Earnest: A Trivial Nov...   \n",
       "1016788   252676    Lilith's Cave: Jewish Tales of the Supernatural   \n",
       "83181     252676                                       The Brethren   \n",
       "957473    252676                                    The Devil's Cat   \n",
       "182440    252676                                           Hideaway   \n",
       "42777     252676                                 Skipping Christmas   \n",
       "740036    252676                                            Vespers   \n",
       "1016790   252676   The Best of Gourmet 1997 (Best of Gourmet, 1997)   \n",
       "794850    252676  Eat More, Weigh Less: Dr. Dean Ornish's Life C...   \n",
       "687193    252676                     Friendship Gifts of Good Taste   \n",
       "705809    252676  Three Complete Novels: Patriot Games, Clear an...   \n",
       "410565    252676                                        Dragonsdawn   \n",
       "329664    252676                                  Another Fine Myth   \n",
       "292428    252676                                       The Attorney   \n",
       "258015    252676                                     Bitter Harvest   \n",
       "121960    252676  Don't Sweat the Small Stuff and It's All Small...   \n",
       "1016792   252676                     Treasury of Campbell's Recipes   \n",
       "\n",
       "         Book-Rating             Book-Author  Year-Of-Publication  \\\n",
       "1016791           10             Anne Geddes                 1997   \n",
       "1016789            8  Editors of Bon Appetit                 1997   \n",
       "533707             8         Charles Osborne                 2000   \n",
       "1016788            7         Howard Schwartz                 1988   \n",
       "83181              7            John Grisham                 2000   \n",
       "957473             6    William W. Johnstone                 1987   \n",
       "182440             5          Dean R. Koontz                 1992   \n",
       "42777              0            JOHN GRISHAM                 2001   \n",
       "740036             0              Jeff Rovin                 1999   \n",
       "1016790            0  The Editors of Gourmet                 1997   \n",
       "794850             0             Dean Ornish                 1997   \n",
       "687193             0              Anne Young                 1992   \n",
       "705809             0              Tom Clancy                 1994   \n",
       "410565             0          Anne McCaffrey                 1989   \n",
       "329664             0           Robert Asprin                 1991   \n",
       "292428             0           Steve Martini                 2001   \n",
       "258015             0                Ann Rule                 1999   \n",
       "121960             0         Richard Carlson                 1997   \n",
       "1016792            0   Campbell Soup Company                 1991   \n",
       "\n",
       "                          Publisher  \n",
       "1016791    Cedco Publishing Company  \n",
       "1016789              Pantheon Books  \n",
       "533707                St Martins Pr  \n",
       "1016788               Harpercollins  \n",
       "83181                        Island  \n",
       "957473                  Zebra Books  \n",
       "182440     Berkley Publishing Group  \n",
       "42777                     Doubleday  \n",
       "740036           St. Martin's Press  \n",
       "1016790          Random House Trade  \n",
       "794850                  HarperTorch  \n",
       "687193            Leisure Arts Inc.  \n",
       "705809      Putnam Publishing Group  \n",
       "410565                Del Rey Books  \n",
       "329664                    Ace Books  \n",
       "292428                   Jove Books  \n",
       "258015                       Pocket  \n",
       "121960                     Hyperion  \n",
       "1016792  Publications International  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find original user ratings\n",
    "u_data=ratings_df[ratings_df['User-ID']==252676].sort_values(by='Book-Rating', ascending=False)\n",
    "u_data[['User-ID','Book-Title','Book-Rating','Book-Author','Year-Of-Publication','Publisher']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>estimated rate</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Partner</td>\n",
       "      <td>0.831829</td>\n",
       "      <td>0440224764</td>\n",
       "      <td>John Grisham</td>\n",
       "      <td>1998</td>\n",
       "      <td>Dell Publishing Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0440224764.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440224764.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440224764.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Poisonwood Bible</td>\n",
       "      <td>0.423609</td>\n",
       "      <td>0060512822</td>\n",
       "      <td>Barbara Kingsolver</td>\n",
       "      <td>2003</td>\n",
       "      <td>HarperTorch</td>\n",
       "      <td>http://images.amazon.com/images/P/0060512822.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060512822.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060512822.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Rainmaker</td>\n",
       "      <td>0.403332</td>\n",
       "      <td>0099271273</td>\n",
       "      <td>John Grisham</td>\n",
       "      <td>1998</td>\n",
       "      <td>Arrow</td>\n",
       "      <td>http://images.amazon.com/images/P/0099271273.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0099271273.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0099271273.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sphere</td>\n",
       "      <td>0.373383</td>\n",
       "      <td>0553702327</td>\n",
       "      <td>Michael Crichton</td>\n",
       "      <td>2001</td>\n",
       "      <td>Random House Audio Publishing Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0553702327.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0553702327.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0553702327.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bag of Bones</td>\n",
       "      <td>0.329327</td>\n",
       "      <td>067102423X</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td>1999</td>\n",
       "      <td>Pocket</td>\n",
       "      <td>http://images.amazon.com/images/P/067102423X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/067102423X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/067102423X.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Book-Title  estimated rate        ISBN         Book-Author  \\\n",
       "1            The Partner        0.831829  0440224764        John Grisham   \n",
       "5   The Poisonwood Bible        0.423609  0060512822  Barbara Kingsolver   \n",
       "10         The Rainmaker        0.403332  0099271273        John Grisham   \n",
       "17                Sphere        0.373383  0553702327    Michael Crichton   \n",
       "19          Bag of Bones        0.329327  067102423X        Stephen King   \n",
       "\n",
       "    Year-Of-Publication                            Publisher  \\\n",
       "1                  1998              Dell Publishing Company   \n",
       "5                  2003                          HarperTorch   \n",
       "10                 1998                                Arrow   \n",
       "17                 2001  Random House Audio Publishing Group   \n",
       "19                 1999                               Pocket   \n",
       "\n",
       "                                          Image-URL-S  \\\n",
       "1   http://images.amazon.com/images/P/0440224764.0...   \n",
       "5   http://images.amazon.com/images/P/0060512822.0...   \n",
       "10  http://images.amazon.com/images/P/0099271273.0...   \n",
       "17  http://images.amazon.com/images/P/0553702327.0...   \n",
       "19  http://images.amazon.com/images/P/067102423X.0...   \n",
       "\n",
       "                                          Image-URL-M  \\\n",
       "1   http://images.amazon.com/images/P/0440224764.0...   \n",
       "5   http://images.amazon.com/images/P/0060512822.0...   \n",
       "10  http://images.amazon.com/images/P/0099271273.0...   \n",
       "17  http://images.amazon.com/images/P/0553702327.0...   \n",
       "19  http://images.amazon.com/images/P/067102423X.0...   \n",
       "\n",
       "                                          Image-URL-L  \n",
       "1   http://images.amazon.com/images/P/0440224764.0...  \n",
       "5   http://images.amazon.com/images/P/0060512822.0...  \n",
       "10  http://images.amazon.com/images/P/0099271273.0...  \n",
       "17  http://images.amazon.com/images/P/0553702327.0...  \n",
       "19  http://images.amazon.com/images/P/067102423X.0...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview recommendations by pure SVD\n",
    "recommend_books_for_user_svd(252676, all_predictions_df, ratings_df, books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Estimated_Rate</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dune (Remembering Tomorrow)</td>\n",
       "      <td>8.919501</td>\n",
       "      <td>0441172717</td>\n",
       "      <td>Frank Herbert</td>\n",
       "      <td>1996</td>\n",
       "      <td>ACE Charter</td>\n",
       "      <td>http://images.amazon.com/images/P/0441172717.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0441172717.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0441172717.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Goblet of Fire (Book 4)</td>\n",
       "      <td>8.863983</td>\n",
       "      <td>0439139600</td>\n",
       "      <td>J. K. Rowling</td>\n",
       "      <td>2002</td>\n",
       "      <td>Scholastic Paperbacks</td>\n",
       "      <td>http://images.amazon.com/images/P/0439139600.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0439139600.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0439139600.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Fellowship of the Ring (The Lord of the Ri...</td>\n",
       "      <td>8.848944</td>\n",
       "      <td>0618346252</td>\n",
       "      <td>J. R. R. Tolkien</td>\n",
       "      <td>2003</td>\n",
       "      <td>Houghton Mifflin Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0618346252.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0618346252.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0618346252.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The Return of the King (The Lord of the Rings,...</td>\n",
       "      <td>8.848271</td>\n",
       "      <td>0618346279</td>\n",
       "      <td>J. R. R. Tolkien</td>\n",
       "      <td>2003</td>\n",
       "      <td>Houghton Mifflin Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0618346279.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0618346279.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0618346279.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lonesome Dove</td>\n",
       "      <td>8.842276</td>\n",
       "      <td>0671795899</td>\n",
       "      <td>Larry McMurtry</td>\n",
       "      <td>1993</td>\n",
       "      <td>Pocket</td>\n",
       "      <td>http://images.amazon.com/images/P/0671795899.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0671795899.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0671795899.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Book-Title  Estimated_Rate  \\\n",
       "0                         Dune (Remembering Tomorrow)        8.919501   \n",
       "2        Harry Potter and the Goblet of Fire (Book 4)        8.863983   \n",
       "9   The Fellowship of the Ring (The Lord of the Ri...        8.848944   \n",
       "21  The Return of the King (The Lord of the Rings,...        8.848271   \n",
       "24                                      Lonesome Dove        8.842276   \n",
       "\n",
       "          ISBN       Book-Author  Year-Of-Publication  \\\n",
       "0   0441172717     Frank Herbert                 1996   \n",
       "2   0439139600     J. K. Rowling                 2002   \n",
       "9   0618346252  J. R. R. Tolkien                 2003   \n",
       "21  0618346279  J. R. R. Tolkien                 2003   \n",
       "24  0671795899    Larry McMurtry                 1993   \n",
       "\n",
       "                   Publisher  \\\n",
       "0                ACE Charter   \n",
       "2      Scholastic Paperbacks   \n",
       "9   Houghton Mifflin Company   \n",
       "21  Houghton Mifflin Company   \n",
       "24                    Pocket   \n",
       "\n",
       "                                          Image-URL-S  \\\n",
       "0   http://images.amazon.com/images/P/0441172717.0...   \n",
       "2   http://images.amazon.com/images/P/0439139600.0...   \n",
       "9   http://images.amazon.com/images/P/0618346252.0...   \n",
       "21  http://images.amazon.com/images/P/0618346279.0...   \n",
       "24  http://images.amazon.com/images/P/0671795899.0...   \n",
       "\n",
       "                                          Image-URL-M  \\\n",
       "0   http://images.amazon.com/images/P/0441172717.0...   \n",
       "2   http://images.amazon.com/images/P/0439139600.0...   \n",
       "9   http://images.amazon.com/images/P/0618346252.0...   \n",
       "21  http://images.amazon.com/images/P/0618346279.0...   \n",
       "24  http://images.amazon.com/images/P/0671795899.0...   \n",
       "\n",
       "                                          Image-URL-L  \n",
       "0   http://images.amazon.com/images/P/0441172717.0...  \n",
       "2   http://images.amazon.com/images/P/0439139600.0...  \n",
       "9   http://images.amazon.com/images/P/0618346252.0...  \n",
       "21  http://images.amazon.com/images/P/0618346279.0...  \n",
       "24  http://images.amazon.com/images/P/0671795899.0...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview recommendations by Funk SVD, default\n",
    "recommend_books_for_user_svd_funk(252676, svd_default_model, ratings_df_adj, books_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview recommendations by Funk SVD, tuned\n",
    "recommend_books_for_user_svd_funk(252676, svd_best_parameters_model, ratings_df_adj, books_df)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
